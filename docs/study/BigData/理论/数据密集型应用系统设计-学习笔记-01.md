# 数据密集型应用系统设计-学习笔记-01

# 第一部分 数据系统基础

​	本书前4章总结了适用于所有数据系统的基本思想，既包括单机运行环境，也包括分布式集群环境：

1. 第1章介绍相关术语与方法，这些术语等将贯穿于全书。例如重点关注的可靠性、可扩展性与可维护性设计目标，以及达到这些目标的基本方法。
2. 第2章对比多种不同的数据模型与査询语言，从开发者角度来看，这些是不同数据库系统最显著的区别，我们也会讨论不同模型的具体适用场景。
3. 第3章深入数据库系统内部的核心存储引擎，详细解析数据库如何设计磁盘布局。针对不同的工作负载如何优化其引擎，而正确的设计选型对系统将产生巨大的影响。
4. 第4章比较不同的数据编码格式和序列化技术，特别是当上层应用需求多变而模型也需要灵活调整时，该如何最佳使用这些技术。

​	之后，在第二部分，我们将转向分布式场景下的一些典型问题和解决方案。

+ 可靠性：容忍硬件、软件失效，人为错误

+ 可扩展性：评测负载与性能，延迟百分位数，吞吐量
+ 可维护性：可运维、简单与可演化性

# 第1章 可靠、可扩展与可维护的系统

​	<u>当今许多新型应用都属于数据密集型(data-intensive)，而不是计算密集型(compute-intensive)</u>。对于这些类型应用，CPU的处理能力往往不是第一限制性因素，关键在于数据量、数据的复杂度及数据的快速多变性。

​	数据密集型应用通常也是基于标准模块构建而成，毎个模块负责单一的常用功能。例如，许多应用系统都包含以下模块：

+ 数据库：用以存储数据，这样之后应用可以再次访问。
+ 高速缓存：缓存那些复杂或操作代价昂贵的结果，以加快下一次访问。
+ 索引：用户可以按关键字搜索数据并支持各种过滤。
+ 流式处理：持续发送消息至另一个进程，处理采用异步方式。
+ 批处理：定期处理大量的累积数据。

## 1.1 认识数据系统

​	越来越多的应用系统需求广泛，单个组件往往无法满足所有数据处理与存储需求。因而需要将任务分解，每个组件负责高效完成其中一部分，多个组件依靠应用层代码驱动有机衔接起来。

​	影响数据系统设计的因素有很多，其中包括相关人员技能和经验水平、遗留系统依赖性、交付周期、对不同风险因素的容忍度、监管合规等。这些因素往往因时因地而异。本书将专注于对大多数软件系统都极为重要的三个问题：

+ 可靠性(Reliability)

  当出现意外情况如硬件、软件故障、人为失误等，系统应可以继续正常运转：虽然性能可能有所降低，但确保功能正确。具体请参阅本章后面的“可靠性”一节。

+ 可扩展性(Scalability)

  随着规模的增长，例如数据量、流量或复杂性，系统应以合理的方式来匹配这种增长，具体请参阅本章后面的“可扩展性”一节。

+ 可维护性(Maintainability)

  随着时间的推移，许多新的人员参与到系统开发和运维，以维护现有功能或适配新场景等，系统都应高效运转。具体请参阅本章后面的“可维护性”一节。

​	很多人对上述目标还欠缺深入的理解。追本溯源，本章后续部分将深入思考可靠性、可扩展性和可维护性，并将介绍各种技术、架构以及算法来实现这些目标。

## 1.2 可靠性

​	每个人脑子里都有一个直观的认识，即什么意味着可靠或者不可靠。对于软件，典型的期望包括：

+ 应用程序执行用户所期望的功能。
+ 可以容忍用户出现错误或者不正确的软件使用方法。
+ 性能可以应对典型场景、合理负载压力和数据量。
+ 系统可防止任何未经授权的访问和滥用。

​	如果所有上述目标都要支持才算“正常工作”，那么我们可以认为可靠性大致意味着：即使发生了某些错误，系统仍可以继续正常工作。

​	可能出错的事情称为错误(faults)或故障，系统可应对错误则称为容错(fault-tolerant)或者弹性(resilient)。前一个词略显误导：似乎暗示着系统可以容忍各种可能的故障类型，显然实际中这是不可能的。举一个夸张一些的例子，如果整个地球(及其上的所有服务器)都被黑洞吞噬，那么要在这个级别容错就意味着必须在宇宙范围内进行系统冗余。试想，这将是天价的预算。<u>因此，容错总是指特定类型的故障，这样的系统才更有实际意义</u>。

​	注意，故障与失效(failure)不完全一致。<u>故障通常被定义为组件偏离其正常规格，而失效意味系统作为一个整体停止，无法向用户提供所需的服务</u>。我们不太可能将故障概率降低到零，因此通常设计容错机制来避免从故障引发系统失效。本书将介绍在不可靠组件基础上构建可靠性系统的相关技术。

​	<u>在这种容错系统中，用于测试目的，可以故意提高故障发生概率，例如通过随机杀死某个进程，来确保系统仍保持健壮</u>。很多关键的bug实际上正是由于错误处理不当而造成的旳。通过这种故意引发故障的方式，来持续检验、测试系统的容错机制，增加对真实发生故障时应对的信心。 Netflix的 Chaos Monkey系统就是这种测试的典型例子。

​	<u>虽然我们通常倾向于容忍故障而不是预防故障，但是也存在“预防胜于治疗”的情况，安全问题就是一例，例如：如果攻击者破坏了系统并窃取了敏感数据，则该事件造成的影响显然无法被撤销</u>。然而，本书主要针对那些影响可以被消除的故障类型，接下来详细介绍。

### 1.2.1 硬件故障

​	当我们考虑系统故障时，<u>对于硬件故障总是很容易想到：硬盘崩溃，内存故障，电网停电，甚至有人误拔掉了网线</u>。任何与大型数据中心合作过的人都可以告诉你，当有很多机器时，这类事情迟早会发生。

​	有研究证明硬盘的平均无故障时间(MTTF)约为10~50年。因此，在一个包括10000个磁盘的存储集群中，我们应该预期平均每天有一个磁盘发生故障。

​	<u>我们的第一个反应通常是为硬件添加冗余来减少系统故障率。例如对磁盘配置RAID，服务器配备双电源，甚至热插拔CPU，数据中心添加备用电源、发电机等。当一个组件发生故障，冗余组件可以快速接管，之后再更换失效的组件</u>。这种方法可能并不能完全防止硬件故障所引发的失效，但还是被普遍采用，且在实际中也确实可以让系统不间断运行长达数年。

​	直到最近，采用硬件冗余方案对于大多数应用场景还是足够的，它使得单台机器完全失效的概率降为非常低的水平。只要可以将备份迅速恢复到新机器上，故障的停机时间在大多数应用中并不是灾难性的。而多机冗余则只对少量的关键应用更有意义，对于这些应用，高可用性是绝对必要的。

​	但是，随着数据量和应用计算需求的增加，更多的应用可以运行在大规模机器之上，随之而来的硬件故障率呈线性增长。例如，对于某些云平台(如 Amazon webServices，AwS)，由于系统强调的是总体灵活性与弹性而非单台机器的可靠性，虚拟机实例经常会在事先无告警的情况下出现无法访问问题。

​	因此，通过软件容错的方式来容忍多机失效成为新的手段，或者至少成为硬件容错的有力补充。这样的系统更具有操作便利性，<u>例如当需要重启计算机时为操作系统打安全补丁，可以每次给一个节点打补丁然后重启，而不需要同时下线整个系统(即滚动升级，详见第4章)</u>。

### 1.2.2 软件错误

​	<u>我们通常认为硬件故障之间多是相互独立的：一台机器的磁盘出现故障并不意味着另一台机器的磁盘也要失效</u>。除非存在某种弱相关(例如一些共性原因，如服务器机架中的温度过高)，否则通常不太可能出现大量硬件组件同时失效的情况。

​	<u>另一类故障则是系统内的软件问题。这些故障事先更加难以预料，而且因为节点之间是由软件关联的，因而往往会导致更多的系统故障</u>。例如：

+ 由于软件错误，导致当输入特定值时应用服务器总是崩溃。例如，2012年6月30日发生闰秒，由于Linux内核中的一个bug，导致了很多应用程序在该时刻发生挂起。
+ 一个应用进程使用了某些共享资源如CPU、内存、磁盘或网络带宽，但却不幸失控跑飞了。
+ 系统依赖于某些服务，但该服务突然变慢，甚至无响应或者开始返回异常的响应。
+ 级联故障，其中某个组件的小故障触发另一个组件故障，进而引发更多的系统问题。

​	导致软件故障的bug通常会长时间处于引而不发的状态，直到碰到特定的触发条件。这也意味着系统软件其实对使用环境存在某种假设，而这种假设多数情况都可以满足，但是在特定情况下，假设条件变得不再成立。

​	软件系统问题有时没有快速解决办法，而只能仔细考虑很多细节，包括认真检査依赖的假设条件与系统之间交互，进行全面的测试，进程隔离，允许进程崩溃并自动重启，反复评估，监控并分析生产环节的行为表现等。<u>如果系统提供某些保证，例如在消息队列中，输岀消息的数量应等于输入消息的数量，则可以不断地检査确认，如发现差异则立即告警</u>。

### 1.2.3 人为失误

​	设计和构建软件系统总是由人类完成，也是由人来运维这些系统。即使有时意图是好的，但人却无法做到万无一失。例如，一项针对大型互联网服务的调查发现，<u>运维者的配置错误居然是系统下线的首要原因，而硬件问题(服务器或网络)仅在10%~25%的故障中有所影响</u>。

​	如果我们假定人是不可靠的，那么该如何保证系统的可靠性呢?可以尝试结合以下多种方法：

+ 以最小出错的方式来设计系统。例如，精心设计的抽象层、API以及管理界面，使“做正确的事情”很轻松，但搞坏很复杂。但是，如果限制过多，人们就会想法来绕过它，这会抵消其正面作用。因此解决之道在于很好的平衡。
+ 想办法分离最容易出错的地方、容易引发故障的接口。特别是，提供一个功能齐全但非生产用的沙箱环境，使人们可以放心的尝试、体验，包括导入真实的数据，万一出现问题，不会影响真实用户。
+ <u>充分的测试：从各单元测试到全系统集成测试以及手动测试。自动化测试已被广泛使用，对于覆盖正常操作中很少出现的边界条件等尤为重要。</u>
+ <u>当出现人为失误时，提倛快速的恢复机制以尽量减少故障影响</u>。例如，快速回滚配置改动，滚动发布新代码(这样任何意外的错误仅会影响一小部分用户)，并提供校验数据的工具(防止旧的计算方式不正确)。
+ <u>设置详细而清晰的监控子系统，包括性能指标和错误率</u>。在其他行业称为遥测(Telemetry)，一旦火箭离开地面，遥测对于跟踪运行和了解故障至关重要监控可以向我们发送告警信号，并检查是否存在假设不成立或违反约束条件等。这些检测指标对于诊断问题也非常有用。
+ 推行管理流程并加以培训。这非常重要而且比较复杂，具体内容已超出本书范围。

### 1.2.4 可靠性的重要性

​	可靠性绝不仅仅针对的是核电站和空中交管软件之类的系统，很多应用都需要可靠工作。商业软件中的错误会导致效率下降(如数据报告错误，甚至带来法律风险)，电子商务网站的暂停会对营收和声誉带来巨大损失。

​	即使在所谓“非关键”应用中，我们也应秉持对用户负责的态度。例如一对父母，将其所有的照片以及他们孩子的视频存放在你的照片应用中。如果不幸发生了数据库损坏，他们的感受可想而知，他们是否知道该如何从备份数据来执行恢复?

​	当然，也会存在其他一些情况，例如面对不太确定的市场开发原型系统，或者服务的利润微薄，有时也会牺牲一些可靠性来降低开发成本或者运营开销，对此，我们总是建议务必三思后行。

## 1.3 可扩展性

​	即使系统现在工作可靠，并不意味着它将来一定能够可靠运转。发生退化的一个常见原因是负载增加：例如也许并发用户从最初的10000个增长到100000个，或从100万到1000万；又或者系统目前要处理的数据量超出之前很多倍。

​	可扩展性是用来描述系统应对负载增加能力的术语。但是请注意，它并不是衡量一个系统的一维指标，谈论“X是可扩展”或“Y不扩展”没有太大意义。相反，<u>讨论可扩展性通常要考虑这类问题：“如果系统以某种方式增长，我们应对增长的措施有哪些”，“我们该如何添加计算资源来处理额外的负载”</u>。

### 1.3.1 描述负载

​	首先，我们需要简洁地描述系统当前的负载，只有这样才能更好地讨论后续增长问题(例如负载加倍会意味着什么)。负载可以用称为负载参数的若干数字来描述。参数的最佳选择取决于系统的体系结构，它可能是Web服务器的每秒请求处理次数，数据库中写入的比例，聊天室的同时活动用户数量，缓存命中率等。<u>有时平均值很重要，有时系统瓶颈来自于少数峰值</u>。

​	我们以Twitter为例，使用其2012年11月发布的数据。 Twitter两个典型业务操作是：

+ 发布tweet消息：用户可以快速推送新消息到所有的关注者，平均大约4.6k request/sec，峰值约12k requests/sec
+ 主页时间线(Home timeline)浏览：平均300k request/sec查看关注对象的最新消息。

​	仅仅处理峰值约12k的消息发送听起来并不难，但是， Twitter扩展性的挑战重点不在于消息大小，而在于巨大的扇出(fan-out)串结构：每个用户会关注很多人，也会被很多人圈粉。此时大概有两种处理方案：

1. 将发送的新tweet插入到全局的tweet集合中。当用户查看时间线时，首先查找所有的关注对象，列出这些人的所有tweet，最后以时间为序来排序合并。如果以下图的关系型数据模型，可以执行下述的 SQL 查询语句：

   ```sql
   SELECT tweets.*,users.* FROM tweets
   JOIN users ON tweets.sender_id = users.id
   JOIN follows ON follows.followee_id = users.id
   WHERE follows.follower_id = current_user
   ```

   ![image.png](https://image-static.segmentfault.com/132/745/1327458763-60167c5753ce0)

2. 对每个用户的时间线维护一个缓存，如图所示，类似每个用户一个 tweet邮箱。当用户推送新 tweet 时，查询其关注者，将tweet插入到每个关注者的时间线缓存中。因为已经预先将结果取出，之后访问时间线性能非常快。

   ![image.png](https://image-static.segmentfault.com/872/753/87275316-60167ced9cac3)

​	Twitter 在其第一个版本使用了方法1，但发现主页时间线的读负载压力与日俱增，系统优化颇费周折，因此转而采用第二种方法。实践发现这样更好，<u>因为时间线浏览 tweet 的压力几乎比发布tweet 要高出两个数量级</u>，基于此，在发布时多完成一些事情可以加速读性能。

​	然而，方法2的缺点也很明显，在发布 tweet 时增加了大量额外的工作。考虑平均 75 个关注者和每秒 4.6k 的 tweet，则需要每秒 4.6k × 75 = 345k 速率写入缓存。但是，75 这个平均关注者背后还隐藏其他事实，即关注者其实偏差巨大，例如某些用户拥有超过 3000 万的追随者。这就意味着峰值情况下一个 tweet 会导致 3000 万笔写入！而且要求尽量快，Twitter 的设计目标是 5s 内完成，这成为一个巨大的挑战。

​	在Twitter的例子中，<u>每个用户关注者的分布情况（还可以结合用户使用 Twitter 频率情况进行加权）是该案例可扩展的关键负载参数，因为它决定了扇出数。其他应用可能具有不同的特性，但可以采用类似的原则来研究具体负载</u>。

​	Twitter 故事最后的结局是：方法 2 已经得到了稳定实现，Twitter 正在转向结合两种方法。<u>大多数用户的 tweet 在发布时继续以一对多写入时间线，但是少数具有超多关注者的用户除外，对这些用户采用类似方案 1，其推文被单独提取，在读取时才和用户的时间线主表合并。这种混合方法能够提供始终如一的良好表现</u>。在我们介绍诸多技术基础之后，我们将在第12章重新审视该例子。

### 1.3.2 描述性能

​	描述系统负载之后，接下来设想如果负载增加将会发生什么。有两种考虑方式：

+ 负载增加，但系统资源(如CPU、内存、网络带宽等)保持不变，系统性能会发生什么变化?
+ 负载增加，如果要保持性能不变，需要增加多少资源?

​	这两个问题都会关注性能指标，所以我们先简要介绍一下如何描述系统性能。在批处理系统如Hadoop中，我们通常关心<u>**吞吐量(throughput)**，即每秒可处理的记录条数，或者在某指定数据集上运行作业所需的总时间</u>；而在线系统通常更看重服务的**响应时间(response time)**，即客户端从发送请求到接收响应之间的间隔。

> **延迟与响应时间**
>
> 延迟(latency)和响应时间(response time)容易混淆使用，但它们并不完全一样。
>
> + <u>通常响应时间是客户端看到的：除了处理请求时间(服务时间， service time)外，还包括来回网络延迟和各种排队延迟</u>。
> + <u>延迟则是请求花费在处理上的时间</u>。

​	即使是反复发送、处理相同的请求，每次可能都会产生略微不同的响应时间。实际情况往往更复杂，由于系统要处理各种不同的请求，响应时间可能变化很大。因此，最好不要将响应时间视为一个固定的数字，而是可度量的一种数值分布。

​	一个例子如图所示，每个灰色条表示一个服务请求，高度表示该请求的响应时间。可以看到，大多数请求是相当快的，但偶尔会有异常表示需要更长的时间。也许这些异常请求确实代价很高，例如它们的数据大很多。但有时，即使所有请求都相同，也会由于其他变量因素而引入一些随机延迟抖动，<u>这些因素包括上下文切换和进程调度、网络数据包丢失和TCP重传、垃圾回收暂停、缺页中断和磁盘IO，甚至服务器机架的机械振动</u>。

​	我们经常考察的是服务请求的平均响应时间(严格来说，术语“平均值”并没有明确釆用何种具体公式，但通常被理解为算术平均值：给定n个值，将所有值相加，并除以n)。然而，如果想知道更典型的响应时间，平均值并不是合适的指标，因为它掩盖了一些信息，无法告诉有多少用户实际经历了多少延迟。

​	<u>因此最好使用百分位数(percentiles)。如果已经搜集到了响应时间信息，将其从最快到最慢排序，中位数(median)就是列表中间的响应时间</u>。例如，如果中位数响应时间为200ms，那意味着有一半的请求响应不到200ms，而另一半请求则需要更长的时间。

​	<u>中位数指标非常适合描述多少用户需要等待多长时间：一半的用户请求的服务时间少于中位数响应时间，另一半则多于中位数的时间。**因此中位数也称为50百分位数，有时缩写为p50**</u>。请注意，中位数对应单个请求；这也意味着如果某用户发了多个请求(例如包含在一个完整会话过程中，或者因为某页面包含了多个资源)，那么它们中至少一个比中位数慢的概率远远大于50%。

​	为了弄清楚异常值有多糟糕，<u>需要关注更大的百分位数如常见的第95、99和99.9(缩写为p95、p99和p999)值。作为典型的响应时间阈值，它们分别表示有95%、99%或99.9%的请求响应时间快于阈值</u>。例如，如果95百分位数响应时间为1.5，这意味着100个请求中的95个请求快于1.5s，而5个请求则需要1.5s或更长时间，如图1-4所示。

​	**采用较高的响应时间百分位数(tail latencies，尾部延迟或长尾效应)很重要，因为它们直接影响用户的总体服务体验**。<u>例如，亚马逊采用99.9百分位数来定义其内部服务的响应时间标准，或许它仅影响1000个请求中的1个。但是考虑到请求最慢的客户往往是购买了更多的商品，因此数据量更大换言之，他们是最有价值的客户</u>。让这些客户始终保持愉悦的购物体验显然非常重要：亚马逊还注意到，响应时间毎增加100ms，销售额就会下降了约1%，其他研究则表明，1s的延迟增加等价于客户满意度下降16%。

​	另一方面，也有人说，优化这个99.99百分位数(10000个请求中最慢的1个)代价昂贵，并没有为亚马逊的商业目标带来足够的收益。进一步提高响应时间技术上代价更大，很容易受到非可控因素如随机事件的影响，累积优势会减弱。

​	例如，**百分位数通常用于措述、定义服务质量目标(Service Level Objectives，SLO)和服务质量协议(Servie Level Agreements，SLA)，这些是规定服务预期质量和可用性的合同**。例如一份SLA合约通常会声明，响应时间中位数小于200ms，99%请求的响应时间小于1s，且要求至少99.9%的时间都要达到上述服务指标。这些指标明确了服务质量预期，并允许客户在不符合SLA的情况下进行赔偿。

​	排队延迟往往在高百分数响应时间中影响很大。<u>由于服务器并行处理的请求有限(例如，CPU内核数的限制)，正在处理的少数请求可能会阻挡后续请求，这种情况有时被称为**队头阻塞**</u>。即使后续请求可能处理很简单，但它阻塞在等待先前请求的完成，客户端将会观察到极慢的响应时间。

​	因此，很重要的一点是要在客户端来测量响应时间。因此，当测试系统可扩展性而人为产生负载时，负载生成端要独立于响应时间来持续发送请求。<u>如果客户端在发送请求之前总是等待先前请求的完成，就会在测试中人为地缩短了服务器端的累计队列深度，这就带来了测试偏差</u>。

### 1.3.3 应对负载增加的方法

​	我们已经讨论了描述负载的参数以及衡量性能的相关指标，接下来讨论可扩展性：即当负载参数增加时，应如何保持良好性能?

> 实践中的百分位数
>
> 对于后台服务，如果一次完整的服务里包含了多次请求调用，此时高百分位数指标尤为重要。即使这些子请求是并行发送、处理，但最终用户仍然需要等待最慢的那个调用完成才行。<u>哪怕一个缓慢的请求处理，即可拖累整个服务</u>。即使只有很小百分比的请求缓慢，如果某用户总是频繁产生这种调用，最终总体变慢的概率就会增加(即长尾效应)。
>
> 最好将响应时间百分位数添加到服务系统监控中，持续跟踪该指标。例如，设置个10min的滑动窗口，监控其中响应时间，滚动计算窗口中的中位数和各种百分位数，然后绘制性能图表。
>
> 一种简单的实现方案是在时间窗口内保留所有请求的响应时间列表，每分钟做次排序。如果这种方式效率太低，可以采用一些近似算法(如正向衰减，t-digest 或 Hdrhistogram)来计算百分位数，其CPU和内存开销很低。同时请注意，降低采样时间精度或直接组合来自多台机器的数据，在数学上没有太大意义，聚合响应时间的正确方法是采用直方图。

​	首先，针对特定级别负载而设计的架构不太可能应付超出预设目标10倍的实际负载。**如果目标服务处于快速增长阶段，那么需要认真考虑每增加一个数量级的负载，架构应如何设计**。

​	现在谈论更多的是**如何在垂直扩展(即升级到更强大的机器)和水平扩展(即将负载分布到多个更小的机器)之间做取舍**。在多台机器上分配负载也被称为**无共享体系结构**。在单台机器上运行的系统通常更简单，然而高端机器可能非常昂贵，且扩展水平有限，最终往往还是无法避免需要水平扩展。实际上，好的架构通常要做些实际取舍，例如，使用几个强悍的服务器仍可以比大量的小型虛拟机来得更简单、便宜。

​	某些系统具有弹性特征，它可以自动检测负载增加，然后自动添加更多计算资源，而其他系统则是手动扩展(人工分析性能表现，之后决定添加更多计算)。<u>如果负载高度不可预测，则自动弹性系统会更加高效，但或许手动方式可以减少执行期间的意外情况</u>(参阅第6章的“分区再平衡”)。

​	**把无状态服务分布然后扩展至多台机器相对比较容易，而有状态服务从单个节点扩展到分布式多机环境的复杂性会大大增加**。<u>出于这个原因，直到最近通常的做法一直是，将数据库运行在一个节点上(采用垂直扩展策略)，直到高扩展性或高可用性的要求迫使不得不做水平扩展</u>。

​	然而，随着相关分布式系统专门组件和编程接口越来越好，至少对于某些应用类型来讲，上述通常做法或许会发生改变。可以乐观设想，即使应用可能并不会处理大量数据或流量，但未来分布式数据系统将成为标配。在本书后续部分，我们将介绍多种分布式数据系统，不仅可以帮助提高可扩展性，也会提高易用性与可维护性。

​	超大规模的系统往往针对特定应用而高度定制，很难有一种通用的架构。背后取舍因素包括数据读取量、写入量、待存储的数据量、数据的复杂程度、响应时间要求、访问模式等，或者更多的是上述所有因素的叠加，再加上其他更复杂的问题。

​	例如，即使两个系统的数据吞吐量折算下来是一样的，但是为每秒处理1000次请求(每个大小为1KB)而设计的系统，与为每分钟3个请求(每个大小为2GB)设计的系统会大不相同。

​	对于特定应用来说，扩展能力好的架构通常会做出某些假设，然后有针对性地优化设计，如哪些操作是最频繁的，哪些负载是少数情况。如果这些假设最终发现是错误的，那么可扩展性的努力就白费了，甚至会出现与设计预期完全相反的情况。<u>对于早期的初创公司或者尚未定型的产品，快速迭代推出产品功能往往比投入精力来应对不可知的扩展性更为重要</u>。

​	可扩展架构通常都是从通用模块逐步构建而来，背后往往有规律可循，所以本书将会讨论这些通用模块和常见模式，希望对读者有所借鉴。

## 1.4 可维护性

​	众所周知，<u>软件的大部分成本并不在最初的开发阶段，而是在于整个生命周期内持续的投入，这包括维护与觖陷修复，监控系统来保持正常运行、故障排査、适配新平台、搭配新场景、技术缺陷的完善以及增加新功能等</u>。

​	不幸的是，许多从业人根本不喜欢维护这些所谓的遗留系统，例如修复他人埋下的错误，或者使用过时的开发平台，或者被迫做不喜欢的工作。坦白说，每一个遗留系统总有其过期的理由，所以很难给出一个通用的建议该如何处理它们。

​	但是，换个角度，我们可以从软件设计时开始考虑，尽可能较少维护期间的麻烦，甚至避免造出容易过期的系统。为此，我们将特别关注软件系统的三个设计原则：

+ 可运维性

  方便运营团队来保持系统平稳运行。

+ 简单性

  简化系统复杂性，使新工程师能够轻松理解系统。注意这与用户界面的简单性并不一样。

+ 可演化性

  后续工程师能够轻松地对系统进行改进，并根据需求变化将其适配到非典型场景，也称为可延伸性、易修改性或可塑性。

​	与可靠性和可扩展性类似，实现上述这些目标也没有简单的解决方案。接下来，我们首先建立对这三个特性的理解。

### * 1.4.1 可运维性：运维更轻松

​	有人认为，“良好的操作性经常可以化解软件的局限性，而不规范的操作则可以轻松击垮软件”。虽然某些操作可以而且应该是自动化的，但最终还是需要人来执行配置并确保正常工作。

​	运营团队对于保持软件系统顺利运行至关重要。一个优秀的运营团队通常至少负责以下内容：

+ 监视系统的健康状况，并在服务出现异常状态时快速恢复服务。
+ 追踪问题的原因，例如系统故障或性能下降。

+ 保持软件和平台至最新状态，例如安全补丁方面。
+ 了解不同系统如何相互影响，避免执行带有破坏性的操作，预测未来可能的问题，并在问题发生之前即使解决(例如容量规划)。
+ 建立用于部署、配置管理等良好的实践规范和工具包。
+ 执行复杂的维护任务，例如将应用程序从一个平台迁移到另一个平台。
+ 当配置更改时，维护系统的安全稳健。
+ 制定流程来规范操作行为，并保持生产环境稳定。
+ 保持相关知识的传承(如对系统理解)，例如发生团队人员离职或者新员工加入等。

​	良好的可操作性意味着使日常工作变得简单，使运营团队能够专注于高附加值的任务。数据系统设计可以在这方面贡献很多，包括：

+ 提供对系统运行时行为和内部的可观测性，方便监控。
+ 支持自动化，与标准工具集成。
+ 避免绑定特定的机器，这样在整个系统不间断运行的同时，允许机器停机维护。
+ 提供良好的文档和易于理解的操作模式，诸如“如果我做了X，会发生Y”。
+ 提供良好的默认配置，且允许管理员在需要时方便地修改默认值。
+ 尝试自我修复，在需要时让管理员手动控制系统状态。
+ 行为可预测，减少意外发生。

### 1.4.2 简单性：简化复杂度

​	小型软件项目通常可以写出简单而漂亮的代码，但随着项目越来越大，就会越来越复杂和难以理解。这种复杂性拖慢了开发效率，增加了维护成本。一个过于复杂的软件项目有时被称为一个“大泥潭“。

​	<u>复杂性有各种各样的表现方式：状态空间的膨胀，模块紧耦合，令人纠结的相互依赖关系，不一致的命名和术语，为了性能而采取的特殊处理，为解决某特定问题而引入的特殊框架等</u>。

​	复杂性使得维护变得越来越困难，最终会导致预算超支和开发进度滞后。对于复杂的软件系统，变更而引入潜在错误的风险会显著加大，最终开发人员更加难以准确理解、评估或者更加容易忽略相关系统行为，包括背后的假设，潜在的后果，设计之外的模块交互等。相反，降低复杂性可以大大提高软件的可维护性，因此简单性应该是我们构建系统的关键目标之一。

​	简化系统设计并不意味着减少系统功能，而主要意味着消除意外方面的复杂性，正如Moseley和Marks把复杂性定义为一种“意外”，即它并非软件固有、被用户所见或感知，而是实现本身所衍生出来的问题。

​	**消除意外复杂性最好手段之一是抽象。一个好的设计抽象可以隐藏大量的实现细节并对外提供干净、易懂的接口**。一个好的设计抽象可用于各种不同的应用程序。这样，复用远比多次重复实现更有效率；另一方面，也带来更高质量的软件，而质量过硬的抽象组件所带来的好处，可以使运行其上的所有应用轻松获益。

​	例如，高级编程语言作为一种抽象，可以隐藏机器汇编代码、CPU寄存器和系统调用等细节和复杂性。SQL作为一种抽象，隐藏了内部复杂的磁盘和内存数据结构，以及来自多客户端的并发请求，系统崩溃之后的不一致等问题。<u>当然，使用高级编程语言最终并没有脱离机器汇编代码，只是并非直接使用，与汇编代码打交道的事情已经由编程语言抽象为高效接口代我们完成。</u>

​	然而，设计好的抽象还是很有挑战性。在分布式系统领域中，虽然已有许多好的算法可供参考，但很多时候我们并不太清楚究竟该如何利用他们，封装到抽象接口之中最终帮助将系统的复杂性降低到可掌控的级别。

​	本书我们将广泛考察如何设计好的抽象，这样至少能够将大型系统的一部分抽象为定义明确、可重用的组件。

### 1.4.3 可演化性：易于改变

​	一成不变的系统需求几乎没有，想法和目标经常在不断变化：适配新的外部环境，新的用例，业务优先级的变化，用户要求的新功能，新平台取代旧平台，法律或监管要求的变化，业务增长促使架构的演变等。

​	在组织流程方面，敏捷开发模式为适应变化提供了很好的参考。敏捷社区还发布了很多技术工具和模式，以帮助在频繁变化的环境中开发软件，例如测试驱动开发(TDD)和重构。

​	这些敏捷开发技术目前多数还只是针对小规模、本地模式(例如同一应用程序中的几个源代码文件)环境。本书将探索在更大的数据系统层面上提高敏捷性，系统由多个不同特性的应用或者服务协作而成。例如，对于 Twitter的案例(参见本章前面的“描述负载”)，如何从方法1过渡到方法2，重构 Twitter架构来实现主页时间线。

​	我们的目标是可以轻松地修改数据系统，使其适应不断变化的需求，这和简单性与抽象性密切相关:简单易懂的系统往往比复杂的系统更容易修改。这是一个非常重要的理念，我们将采用另一个不同的词来指代数据系统级的敏捷性，即可演化性。

## 1.5 小结

​	这一章我们探讨了一些关于数据密集型应用的基本原则，这些原则将指导如何阅读本书的其余部分。

​	一个应用必须完成顸期的多种需求，主要包括功能性需求(即应该做什么，比如各种存储、检索、搜索和处理数据)和一些非功能性需求(即常规特性、例如安全性、可靠性、合规性、可伸缩性、兼容性和可维护性)。本章我们着重梳理讨论了可靠性、可扩展性和可维护性。

​	可靠性意味着即使发生故障，系统也可以正常工作。故障包括硬件(通常是随机的，不相关的)、软件(缺陷通常是系统的，更加难以处理)以及人为(总是很难避免时不时会岀错)方面。容错技术可以很好地隐藏某种类型故障，避免影响最终用户。

​	可扩展性是指负载增加时，有效保持系统性能的相关技术策略。为了讨论可扩展性，我们首先探讨了如何定量描述负载和性能。简单地以Twitter浏览时间线为例描述负载，并将响应时间百分位数作为衡量性能的有效方式。对于可扩展的系统，增加处理能力的同时，还可以在高负载情况下持续保持系统的高可靠性。	

​	可维护性则意味着许多方面，但究其本质是为了让工程和运营团队更为轻松。良好的抽象可以帮助降低复杂性，并使系统更易于修改和遹配新场景。良好的可操作性意味着对系统健康状况有良好的可观测性和有效的管理方法。

​	然而知易行难，使应用程序可靠、可扩展或可维护并不容易。考虑到一些重要的模式和技术在很多不同应用中普遍适用，在接下来的几章中，我们就一些数据密集系统例子，分析它们如何实现上述这些目标。

# 第2章 数据模型与查询语句

## 2.1 关系模型与文档模型

​	现在最著名的数据模型可能是SQL，它基于 Edgar codd于1970年提出的关系模型数据被组织成关系(relations)，在SQL中称为表( table)，其中每个关系都是元组( tuples)的无序集合(在SQL中称为行)。

​	关系模型曾经只是一个理论建议，当时很多人怀疑它是否能够被高效地实现。然而，到了20世纪80年代中期，关系数据库管理系统( RDBMS)和SQL已经成为大多数需要存储、査询具有某种规则结构数据的首选工具。关系数据库的主导地位已经持续了25~30年，这在计算机历史称得上一段不朽传奇。

​	关系数据库的核心在于商业数据处理，20世纪60年代和70年代主要运行在大型计算机之上。从今天的角度来看，用例看起来很常见，主要是事务处理(包括输入销售和银行交易、航空公司订票、仓库库存)和批处理(例如客户发票、工资单、报告)。

​	当时的其他数据库迫使应用开发人员考虑数据的内部表示。关系模型的目标就是将实现细节隐藏在更简洁的接口后面。

​	多年来，在数据存储和查询方面存在着其他许多竞争技术。在20世纪70年代和80年代初期，网络模型和层次模型是两个主要的选择，但最终关系模型主宰了这个领域。对象数据库曾在20世纪80年代后期和90年代初期起起伏伏。ⅩML数据库则出现在2世纪初，但也仅限于利基市场。关系模型的每个竞争者都曾聒噪一时，可惜无一持久。

​	随着计算机变得越来越强大和网络化，服务目的日益多样化。值得注意的是，关系数据库超出了它们最初的商业数据处理范围，顺利推广到了各种各样的用例。当前在网上看到的大部分内容很多仍然是由关系数据库所支撑的，无论是在线发布、论坛、社交网络、电子商务、游戏、SaaS等。

 ### 2.1.1 NoSQL的诞生

​	进入21世纪， NoSQL成为推翻关系模式主导地位的又一个竞争者。“ NoSQL”这个名字是不恰当的，因为它其实并不代表具体的某些技术，它最初只是作为一个吸引人眼球的 Twitter标签频频出现在2009年的开源、分布式以及非关系数据库的见面会上。尽管如此，这个称呼还是让人有所触动，并迅速传遍了网络创业社区。现在很多新兴的数据库系统总是会打上 NoSQL的标签，而其含义也已经被逆向重新解释为“不仅仅是SQL”。

​	采用NoSQL数据库有这样几个驱动因素，包括：

+ 比关系数据库更好的扩展性需求，包括**支持超大数据集**或**超高写入吞吐量**。
+ 普遍偏爱免费和开源软件而不是商业数据库产品。
+ 关系模型不能很好地支持一些特定的查询操作。
+ 对关系模式一些限制性感到沮丧，渴望更具动态和表达力的数据模型。

​	不同的应用程序有不同的需求，某个用例的最佳的技术选择未必适合另一个用例。因此，在可预见的将来，关系数据库可能仍将继续与各种非关系数据存储一起使用，这种思路有时也被称为混合持久化的。

### 2.1.2 对象-关系不匹配

​	**现在大多数应用开发都采用面向对象的编程语言，由于兼容性问题，普遍对SQL数据模型存在抱怨：如果数据存储在关系表中，那么应用层代码中的对象与表、行和列的数据库模型之间需要一个笨拙的转换层**。模型之间的脱离有时被称为**阻抗失谐**。

​	ActiveRecord 和 Hibernate 这样的对象-关系映射(ORM)框架则减少了此转换层所需的样板代码量，但是他们并不能完全隐藏两个模型之间的差异。

![28b8074d8e72d62db47420b144496bb8.png](https://img-blog.csdnimg.cn/img_convert/28b8074d8e72d62db47420b144496bb8.png)

​	一些开发人员认为JSON模型减少了应用程序代码和存储层之间的阻抗失配。然而正如我们将在第4章中看到的那样，JSON作为数据编码格式也存在问题。缺乏模式常常被认为是一个优势；我们将在本章后面“文档模型的模式灵活性”中讨论这个问题。

​	JSON表示的多表模式具有更好的局部性。如果要在关系模式中读取一份简历，那么要么执行多个查询(通过 user id查询每个表)，要么在 users表及其从属表之间执行混乱的多路联结。而对于JSON表示方法，所有的相关信息都在一个地方次查询就够了。

​	用户简历到用户的职位、教育历史和联系信息的一对多关系，意味着数据存在树状结构，JSON表示将该树结构显式化。

![7d0c6211074b0eb8fe9f796b4b89a3ba.png](https://img-blog.csdnimg.cn/img_convert/7d0c6211074b0eb8fe9f796b4b89a3ba.png)

### 2.1.3 多对一与多对多的关系

​	在示例中， region_id 和 industry_id定义为ID，而不是纯文本字符串形式，例如"Greater Seattle Area"和" Philanthropy"。为什么这样做呢?

​	如果用户界面是可以输入地区或行业的自由文本字段，则将其存储为纯文本字符串更有意义。但是，拥有地理区域和行业的标准化列表，并让用户从下拉列表或自动填充器中进行选择会更有优势，这样：

+ 所有的简历保持样式和输入值一致。
+ 避免歧义(例如，如果存在一些同名的城市)。
+ 易于更新：名字只保存一次，因此，如果需要改变(例如，由于政治事件而更改城市名称)，可以很容易全面更新。
+ 本地化支持：当网站被翻译成其他语言时，标准化的列表可以方便本地化，因此地区和行业可以用查看者的母语来显示。
+ 更好的搜索支持:例如，搜索华盛顿州的慈善家可以匹配到这个简历，这是因为地区列表可以将西雅图属于华盛顿的信息编码进来(而从“大西雅图地区”字符串中并不能看出来西雅图属于华盛顿)。

​	<u>无论是存储ID还是文本字符串，都涉及内容重复的问题。当使用ID时，对人类有意义的信息(例如慈善这个词)只存储在一个地方，引用它的所有内容都使用ID(I只在数据库中有意义)。当直接存储文本时，则使用它的毎条记录中都保存了一份这样可读信息</u>。

​	<u>使用ID的好处是，因为它对人类没有任何直接意义，所以永远不需要直接改变：即使ID标识的信息发生了变化，它也可以保持不变。任何对人类有意义的东西都可能在将来某个时刻发生变更。如果这些信息被复制，那么所有的冗余副本也都需要更新。这会导致更多写入开销，并且存在数据不一致的风险(信息的一些副本被更新，而其他副本未更新)</u>。消除这种重复正是数据库规范化的核心思想。

>数据库管理员和开发人员有时喜欢争论规范化与反规范化，此处我们暂不做评论。在本书的第三部分，我们将重回这个话题，并探索处理缓存、反规范化和派生数据更为系统化的方法。

​	然而这种数据规范化需要表达多对一的关系(许多人生活在同一地区，许多人在同行业工作)，这并不是很适合文档模型。对于关系数据库，由于支持联结操作，可以很方便地通过ID来引用其他表中的行。而在文档数据库中，一对多的树状结构不需要联结，支持联结通常也很弱。

​	如果数据库本身不支持联结，则必须在应用程序代码中，通过对数据库进行多次查询来模拟联结(对于上述例子，地区和行业的列表很小且一段时间内不太可能发生变化，应用程序可以简单地将它们缓存在内存中。但无论如何，联结的工作其实从数据库转移到了应用层)。

​	即使应用程序的初始版本非常适合釆用无联结的文档模型，但随着应用支持越来越多的功能，数据也变得更加互联一体化。

### 2.1.4 文档数据库是否在重演历史？

​	虽然关系数据库中经常使用多对多的关系和联结，但文档数据库和NoSQL再次引发了如何最佳表示数据关系的争论。而类似争论并不是第一次，事实上，它可以追溯到最早的计算机数据库系统。

​	20世纪70年代最受欢迎的商业数据处理数据库是IBM信息管理系统( InformationManagement System，IMS)，最初是为了阿波罗太空计划中的库存管理而开发的，并于1968年首次商业发布。至今它仍在维护和使用，通常运行在IBM大型机OS/390。

​	IMS采用了相当简单的数据模型，称为层次模型，它与文档数据库使用的JSON模型有些显著的相似之处。它将所有数据表示为嵌套在记录中的记录(树)，与JSON结构非常相似。

​	和文档数据库类似，IMS可以很好地支持一对多关系中，但是它支持多对多关系则有些困难，而且不支持联结。开发人员必须决定是复制(反规范化)多份数据，还是手动解析记录之间的引用。20世纪六七十年代的这些问题与开发人员今天遇到的文档数据库的问题非常相似。

​	为了解决层次模型的局限性，之后又提出了多种解决方案。其中最著名的是关系模型( relational model，后来演变成为SQL，并被广泛接受)和网络模型(network model，最初有很多拥趸，可惜最终被人们淡忘)。在20世纪70年代，这两个阵营之间的“大辩论”持续了很长时间。

####  网络模型

​	网络模型由一个称为数据系统语言会议(Conference on Data System Languages，CODASYL)的委员会进行标准化，并由多个不同的数据库厂商实施，它也被称为CODASYL模型。

​	CODASYL模型是层次模型的推广。在层次模型的树结构中，每个记录只有一个父结点；而在网络模型中，一个记录可能有多个父结点。例如，“大西雅图地区”可能有个记录，居住在该地区的每个用户都链接指向它。从而支持对多对一和多对多的关系进行建模。

​	在网络模型中，记录之间的链接不是外键，而更像是编程语言中的指针(会存储在磁盘上)。访问记录的唯一方法是选择一条始于根记录的路径，并沿着相关链接依次访问。这条链接链条也因此被称为访问路径。

​	在最简单的情况下，访问路径像是遍历链表：从链表的头部开始，一次査看一个记录，直到找到所需的记录。但是在一个多对多关系的世界里，存在多条不同的路径通向相同的记录，使用网络模型的程序员必须在脑海中设法跟踪这些不同的访问路径。

​	CODASYL中的査询通过遍历记录列表，并沿着访问路径在数据库中移动游标来执行。如果记录有多个父结点(即来自其他记录的多个传入指针)，则应用程序代码必须跟踪所有关系。甚至 CODASYL委员会的成员也承认，这就像在一个n维数据空间中进行遍历。

​	在20世纪70年代，尽管手动路径选择能够最有效地利用当时非常有限的硬件资源(例如磁带驱动器，搜索速度非常慢)，**但最大的问题在于它们使査询和更新数据库变得异常复杂而没有灵活性**。<u>无论是层次模型还是网络模型，如果脱离数据的访问路径那么将寸步难行</u>。它也支持改变访问路径，但随之需要大量的手写数据库查询代码重新实现处理新的访问路径。总之，对应用程序的数据模型进行更改是一件非常困难的事情。

#### 关系模型

​	相比之下，关系模型所做的则是定义了所有数据的格式：关系(表)只是元组(行)的集合，仅此而已。没有复杂的嵌套结构，也没有复杂的访问路径。可以读取表中的任何一行或者所有行，支持任意条件查询。可以指定某些列作为键并匹配这些列来读取特定行。可以在任何表中插入新行，而不必担心与其他表之间的外键关系。

​	<u>在关系数据库中，査询优化器自动决定以何种顺序执行査询，以及使用哪些索引。这些选择实际上等价于“访问路径”，但最大的区别在于它们是由查询优化器自动生成的，而不是由应用开发人员所维护，因此不用过多地考虑它们</u>。

​	如果想用新的方式查询数据，只需声明一个新的索引，査询会自动使用最合适的索引。不需要更改查询即可利用新的索引(另请参阅本章后面的“数据查询语言”部分)。因此，关系模型使得应用程序添加新功能变得非常容易。

​	关系数据库的査询优化器称得上是一个复杂的怪兽，研究开发人员多年来持续投入，花费巨大。不管怎样，**关系模型的一个核心要点是：只需构建一次查询优化器，然后使用该数据库的所有应用程序都可以从中受益**。<u>如果没有查询优化器，那么为特定査询手动编写访问路径比编写通用优化器更容易，但从长远来看，通用解决方案更胜一筹</u>。

####  文档数据库的比较

​	从以下角度来看，文档数据库是某种方式的层次模型：即在其父记录中保存了嵌套记录(一对多关系)，而不是存储在单独的表中。

​	**但是，在表示多对一和多对多的关系时，关系数据库和文档数据库并没有根本的不同：在这两种情况下，相关项都由唯一的标识符引用，该标识符在关系模型中被称为外键，在文档模型中被称为文档引用**。标识符可以査询时通过联结操作或相关后续查询来解析。迄今为止，文档数据库并未遵循 CODASYL 标准。

### 2.1.5 关系数据库与文档数据库现状

​	在比较关系数据库与文档数据库时，需要考虑很多方面的差异，包括它们的容错性参阅第5章)和并发处理(参阅第7章)。本章将只关注数据模型中的差异。<u>**支持文档数据模型的主要论点是模式灵活性**，由于**局部性**而带来较好的性能，对于某些应用来说，它更接近于应用程序所使用的数据结构</u>。**关系模型则强在联结操作、多对一和多对多关系更简洁的表达上，与文档模型抗衡**。

#### 哪种数据模型的应用代码更简单？

​	**如果应用数据具有类似文档的结构(即一对多关系树，通常一次加载整个树)，那么使用文档模型更为合适**。而关系型模型则倾向于某种数据分解，它把文档结构分解为多个表，有可能使得模式更为笨重，以及不必要的应用代码复杂化。

​	文档模型也有一定的局限性：例如，不能直接引用文档中的嵌套项，而需要说“用户251的职位列表中的第二项”(非常类似于层次模型中的访问路径)。然而，只要文档嵌套不太深，这通常不是问题。<u>在文档数据库中，对联结的支持不足是否是问题取决于应用程序</u>。例如，在使用文档数据库记录事件发生时间的应用分析程序中，可能永远不需要多对多关系。

​	但是，如果应用程序确实使用了多对多关系，那么文档模型就变得不太吸引人。<u>可以通过反规范化来减少对联结的需求，但是应用程序代码需要做额外的工作来保持非规范化数据的一致性</u>。**通过向数据库发出多个请求，可以在应用程序代码中模拟联结，但是这也将应用程序变得复杂，并且通常比数据库内的专用代码执行的联结慢**。在这些情况下，使用文档模型会导致应用程序代码更复杂、性能更差。

​	通常无法一概而论哪种数据模型的应用代码更简单。这主要取决于数据项之间的关系类型。**对于高度关联的数据，文档模型不太适合，关系模型可以胜任，而图模型(参阅本章后面的“图状数据模型”)则是最为自然的**。

#### 文档模型中的模式灵活性

​	大多数文档数据库，以及关系数据库中的JSON支持，都不会对文档中的数据强制执行任何模式。关系数据库中的XML通常支持带有可选的模式验证功能。<u>没有模式意味着可以将任意的键-值添加到文档中，并且在读取时，客户端无法保证文档可能包含哪些字段</u>。

​	文档数据库有时被称为无模式，但这具有误导性，因为读数据的代码通常采用某种结构因而存在某种隐形模式，而不是由数据库强制执行。<u>更准确的术语应该是读时模式(数据的结构是隐式的，只有在读取时才解释)，与写时模式(关系数据库的一种传统方法，模式是显式的，并且数据库确保数据写入时都必须遵循)相对应</u>。

​	**读时模式类似编程语言中的动态(运行时)类型检査，而写时模式类似于静态(编译时)类型检查**。正如静态与动态类型检查的支持者对于它们的优缺点存在很大的争议，数据库的模式执行也是一个有争议的话题，通常没有明确正确或错误的答案。

​	当应用程序需要改变数据格式时，这些方法之间的差异就变得尤其明显。例如，当前用户的全名存储在一个字段中，而现在想分别存储名字和姓氏。在文档数据库中，只需使用新字段来编写新文档，并在应用层来处理读取旧文档的情况。例如：

```java
if(user && user.name && !user.first_name) {
  // 2013年12月8日之前写的文档，不存在first_name
  user.first_name = user.name.split("")[0];
}
```

​	而对于"静态类型"数据库模式中，通常会按照以下方式执行升级（migration）：

```sql
ALTER TABLE users ADD COLUMN first_name text;
UPDATE users SET first_name = split_part(name, ' ', 1);  -- PostgreSQL
UPDATE users SET first_name = substring_index(name, ' ', 1); -- MySQL
```

​	模式更改由于速度慢并且需要停机，因而评价不高。但这种坏名声其实并不太公平：大多数关系数据库系统可以在几亳秒内执行ALTER TABLE语句。 **MySQL则需要注意，它执行ALTER TABLE时会把现在的整张表复制，因而当表很大时可能会需要几分钟甚至几小时的停机时间，尽管现在有各种辅助工具可以解决这个限制**。

​	<u>在大表上运行UPDATE语句，对于任何数据库都可能会很慢，因为每一行都需要重写。如果这是不可接受的，应用程序可以将 first_name设置为默认值NULL，并在读取时填充它，就像使用文档数据库一样</u>。

​	如果集合中的项由于某种原因(例如数据异构)，并不都具有相同的结构，例如：

+ 有许多不同类型的对象，将每种类型的对象都保存在各自的表中不太现实。
+ 数据的结构由无法控制的外部系统所决定，而且可能随时改变。

​	在这些情况下，模式带来的损害大于它所能提供的帮助，无模式文档可能是更自然的数据模型。但是，**当所有记录都有相同结构时，模式则是记录和确保这种结构的有效机制**。我们将在第4章更详细地讨论模式和模式演变。

#### 查询的数据局部性

​	文档通常存储为编码为JSON、XML或其二进制变体(如 MongoDB的BSON)的连续字符串。<u>如果应用程序需要频繁访问整个文档(例如，在网页上呈现它)，则存储局部性具有性能优势</u>。如果数据被划分在多个表中，则需要进行多次索引査找来检索所有数据，中间可能需要更多的磁盘I/O并花费更多的时间。

​	**局部性优势仅适用需要同时访问文档大部分内容的场景**。<u>由于数据库通常会加载整个文档，如果应用只是访向其中的一小部分，则对于大型文档数据来讲就有些浪费</u>。<u>对文档进行更新时，通常会重写整个文档，而只有修改量不改变源文档大小时，原地覆盖更新才更有效。因此，通常建议文档应该尽量小且避免写入时增加文档大小。这些性能方面的不利因素大大限制了文档数据库的适用场景</u>。

​	值得指出的是，将相关数据归为一组的局部性想法并不仅见于文档模型。例如，Google的Spanner数据库在关系数据模型中提供了相同的局部性，支持模式声明某些表的行应该在父表内交错(嵌套)。 Oracle支持类似的操作，称为“多表索引集群表”特性， Bigtable数据模型(用于Cassandra和Hbase)中的列族概念类似。

​	我们将在第3章介绍更多局部性相关内容。

#### 文档数据库与关系数据库的融合

​	自2000年中期以来，大多数关系数据库系统(MySQL除外)都支持XML。其中包括对XML文档进行本地修改，在XML文档中进行索引和查询等，这样应用程序可以获得与文档数据库非常相似的数据模型。

​	PostgreSQL版本9.3、MyQL版本5.7以及 IBM DB2 10.5，都对JSON文档提供了相应支持。考虑到JSON在 Web Api中非常流行，其他关系数据库很可能将很快增加JSON支持。

​	文档数据库方面， RethinkDB的査询接口支持和关系型类似的联结，而一些MongoDB驱动程序可以自动解析数据库的引用关系(在客户端执行高效联结，注意，因为需要额外的网络往返，且优化程度较低，因此绝对性能可能慢于数据库端执行)。

​	随着时间的推移，似乎关系数据库与文档数据库变得越来越相近，或许这是一件好事：数据模型可以相互补充。如果数据库能够很好处理文档类数据，还能对其执行关系査询，那么应用程序可以使用最符合其需求的功能的组合。

​	融合关系模型与文档模型是未来数据库发展的一条很好的途径。

## 2.2 数据查询语言

​	当关系模型是初被引入时，就包含了査询数据的新方法:SQL是一种声明式查询语言，而IMS和 CODASYL则是命令式。

​	声明式查询语言很有吸引力，它比命令式API更加简洁和容易使用。但更重要的是，它对外隐藏了数据库引擎的很多实现细节，这样数据库系统能够在不改变査询语句的情况下提高性能。

​	**声明式语言通常适合于并行执行**。现在CPU主要通过增加核，而不是通过比之前更高的时钟频率来提升速度。而命令式代码由于指定了特定的执行顺序，很难在多核和多台机器上并行化。<u>声明式语言则对于并行执行更为友好，它们仅指定了结果所满足的模式，而不指定如何得到结果的具体算法。所以如果可以的话，数据库都倾向于采用并行方式实现查询语言</u>。

#### Web上的声明式查询

​	对于Web浏览器的例子，使用声明式CSS样式表比用 JavaScript命令式地操作样式好得多。类似地，在数据库中，像SQL这样的声明式查询语言比命令式查询APIs要好得多。

#### MapReduce查询

​	MapReduce既不是声明式查询语言，也不是一个完全命令式的查询API，而是介于两者之间：査询的逻辑用代码片段来表示，这些代码片段可以被处理框架重复地调用。它主要基于许多函数式编程语言中的map(也称为 collect)和reduce(也称为fold或inject)函数。

​	MapReduce是一个相当底层的编程模型，用于在计算集群上分布执行。而SQL这样的更高层次的查询语言可以通过一些MapReduce操作pipeline来实现(参阅第10章)，当然也有很多SQL的分布式实现并不借助 MapReduce。请注意，SQL并没有任何限制规定它只能在单个机器上运行，而MapReduce也并非垄断了分布式查询。

## 2.3 图状数据模型

​	我们之前看到，多对多关系是不同数据模型之间的重要区别特征。如果数据大多是一对多关系(树结构数据)或者记录之间没有关系，那么文档模型是最合适的。

​	但是，如果多对多的关系在数据中很常见呢？**关系模型能够处理简单的多对多关系，但是随着数据之间的关联越来越复杂，将数据建模转化为图模型会更加自然**。

​	图由两种对象组成：顶点(也称为结点或实体)和边(也称为关系或弧)。很多数据可以建模为图。典型的例子包括：

+ 社交网络

  顶点是人，边指示哪些人彼此认识。

+ Web图

  顶点是网页，边表示与其他页面的HTML链接。

+ 公路或铁路网

  顶点是交叉路口，边表示他们之间的公路或铁路线。

​	有很多著名的算法可以在这些图上运行。例如，汽车导航系统搜索道路网中任意两点之间的最短路径， PageRank可以计算Web图上网页的流行度，从而确定搜索排名。

​	在刚才给出的示例中，图的顶点表示相同类型的事物(分别是人、网页或交叉路口)。然而，图并不局限于这样的同构数据，图更为强大的用途在于，提供了单个数据存储区中保存完全不同类型对象的一致性方式。例如， Facebook维护了一个包含许多不同类型的顶点与边的大图：顶点包括人、地点、事件、签到和用户的评论；边表示哪些人是彼此的朋友，签到发生在哪些位置，谁评论了哪个帖子，谁参与了哪个事件等。

### 属性图

在属性图模型中，每个顶点包括：

+ 唯一的标识符。
+ 出边的集合。
+ 入边的集合。
+ 属性的集合(键-值对)。

每个边包括：

+ 唯一的标识符。
+ 边开始的顶点(尾部顶点)。
+ 边结束的顶点(头部顶点)。
+ 描述两个顶点间关系类型的标签。
+ 属性的集合(键-值对)。

​	可以将图存储看作由两个关系表组成，一个用于顶点，另一个用于边。为每个边存储头部和尾部顶点，如果想要顶点的入边或出边的集合，可以分别通过head_vertex或tail_vertex来查询edges表。

​	示例：使用关系模式来表示属性图

```sql
CREATE TABLE vertices (
	vertex_id	integer PRIMARY KEY,
	properties	json
);

CREATE TABLE edges (
	edge_id integer PRIMARY KEY,
  tail_vertex integer REFERENCES vertices (vertex_id),
  head_vertex integer REFERENCES vertices (vertex_id),
  label	text,
  properties	json
);

CREATE INDEX edges_tails ON edges (tail_vertex);
CREATE INDEX edges_heads ON edges (head_vertex);
```

​	关于图模型一些值得注意的地方：

1. 任何顶点都可以连接到其他任何顶点。没有模式限制哪种事物可以或不可以关联。
2. 给定某个顶点，可以高效地得到它的所有入边和出边，从而遍历图，即沿着这些顶点链条一直向前或向后。
3. 通过对不同类型的关系使用不同的标签，可以在单个图中存储多种不同类型的信息，同时仍然保持整洁的数据模型。

![img](https://upload-images.jianshu.io/upload_images/10879214-aed5376d57a74a8b.png?imageMogr2/auto-orient/strip|imageView2/2/w/597/format/webp)

​	这些特性为数据建模提供了很大的灵活性，如图所示。图中显示了一些传统关系模式难以表达的东西，例如不同国家的不同类型的地区结构(法国有省和区，而美国有县和州)，特殊历史原因，以及不同粒度的数据(Lucy当前住所被指定为一个城市，而她的出生地则是州一级)。

​	可以把这个图扩展到包括许多关于Lucy和 Alain的其他信息，或者其他人。例如，可以用它来表示他们的任何食物过敏(通过为每个过敏源引入顶点，以及人与过敏原之间的边来表示过敏)，并将过敏源与顶点的集合联结，这些顶点显示哪些食物含有哪些物质。然后，可以编写一个查询找出每个人吃什么是安全的。图有利于演化：向应用程序添加功能时，图可以容易地扩展以适应数据结构的不断变化。

### Cypher查询语言

​	Cypher是属性图的声明性查询语言，为Neo4j图形数据库创建（它以电影The Matrix中的角色命名，与密码学中的密码无关）。

​	例2-3显示了将图2-5的左边部分插入图形数据库中的Cypher查询。 图的其余部分可以类似地添加，为了便于阅读而省略。 每个顶点都有一个符号名称，例如USA或Idaho，查询的其他部分可以使用这些名称在顶点之间创建边，使用箭头符号：`(Idaho) -[:WITHIN]-> (USA)`创建边 标记为WITHIN，Idaho为尾节点，USA为头节点。

   例2-3。 图2-5中的数据子集，表示为Cypher查询：

```cypher
CREATE 
(NAmerica:Location {name:'North America', type:'continent'}), 
(USA:Location {name:'United States', type:'country' }), 
(Idaho:Location {name:'Idaho', type:'state' }), 
(Lucy:Person {name:'Lucy' }), 
(Idaho) -[:WITHIN]-> (USA) -[:WITHIN]-> (NAmerica), 
(Lucy) -[:BORN_IN]-> (Idaho)
```

​    当图2-5的所有顶点和边被添加到数据库时，我们可以开始提出有趣的问题：例如，查找从美国移民到欧洲的所有人的姓名。 更确切地说，在这里我们想要找到所有在美国有一个BORN_IN边缘的顶点，还有一个LIVING_IN边缘到欧洲的一个位置，并返回每个顶点的name属性。

​    例2-4展示了如何在Cypher中表达该查询。 在MATCH子句中使用相同的箭头符号来查找图中的模式：`(person) -[:BORN_IN]-> ()` 通过标记为BORN_IN的边匹配任何两个相关的顶点。 该边的尾部顶点被绑定到变量person，并且顶部顶点未被命名。

​    例2-4：Cypher查询寻找从美国移民到欧洲的人员名单

```cypher
MATCH 
(person) -[:BORN_IN]-> () -[:WITHIN*0..]-> (us:Location {name:'United States'}), 
(person) -[:LIVES_IN]-> () -[:WITHIN*0..]-> (eu:Location {name:'Europe'})
RETURN person.name
```

​    该查询可以被读取如下：   

​    找到满足以下两个条件的任何顶点（称之为person）：

1. person有一个到其他顶点的出边 BORN_IN。从该顶点开始，可以沿着一系列出边WITHIN，直到最终到达类型为Location的顶点，name属性为"United States"。
2. 同一个person顶点也有一个出边LIVES_IN。沿着这条边，然后是一系列出边WITHIN，最终到达类型为 Location的顶点，name属性为"Europe"。

​	对于每个这样的顶点，返回name属性。

​    其实有多种可行的方法执行上述查询。这里给出的方案是，首先扫描数据库中的所有person，检查每个person的出生地和居住地，然后只返回符合条件的person。

​	当然也可以采用其他等价方式，例如可以从两个Location顶点开始。如果name属性上有索引，则可以高效地找到代表美国和欧洲的两个顶点。然后，通过沿着所有的WITHIN入边，可以继续查找美国和欧洲的所有地点(州、地区、城市等)。最后，根据某个位置顶点的入边 BORN IN或 LIVES IN来找到符合条件的人员。

​	对于声明式査询语言，通常在编写査询语句时，不需要指定执行细节：查询优化器会自动选择效率最高的执行策略，因此开发者可以专注于应用的其他部分。

### SQL中的图查询

​	示例2-2表明可以采用关系数据库表示图数据。如果把图数据放在关系结构中，是否意味着也可以支持SQL查询呢?

​	答案是肯定的，但存在一些困难。**在关系数据库中，通常会预先知道查询中需要哪些join操作。而对于图查询，在找到要查找的顶点之前，可能需要遍历数量未知的边，也就是说，join操作数量并不是预先确定的**。

​	对于示例2-4，这主要集中在 Cypher查询的`()-[: WITHIN * 0 ..]->()`规则中个人的 LIVES_IN边可以指向任何类型的位置，例如街道、城市、地区、区域、国家等。城市可以位于(WIHIN)某地区内，地区可以位于(WIHIN)某州内，州位于(WIHIN)国家内等。 LIVES_IN边可以直接指向正在查找的位置顶点，也可以是位置层次结构中删除的某些层。

​	Cypher可以用: `WITHIN*0..`非常简洁地表达这个情况：它表示“沿着一个WITHIN边，遍历零次或多次”，就像正则表达式中的\*运算符(表示匹配零次或多次)那样。

​	SQL:1999标准以后，査询过程中这种可变的遍历路径可以使用称为递归公用表表达式(即 WITH RECURSIVE语法)来表示。示例2-5采用该技术的SQL表达来执行相同的查询(查找从美国移民到欧洲的人员名单)，目前 PostgreSQL、 IBM DB2、 Oracle和SQL Server等都支持该技术，但与 Cypher相比，语法仍显得非常笨拙。

 例2-5。 与例2-4相同的查询，使用递归公用表达式在SQL中表达：

![img](https://upload-images.jianshu.io/upload_images/10879214-d0204aecb72fd4e4.png?imageMogr2/auto-orient/strip|imageView2/2/w/712/format/webp)

1. 首先找到name属性值为" United States"的顶点，并将其作为顶点集in_usa中的第一个元素。
2. 沿着集合in_usa中顶点的所有入边within，并将它们添加到同一集合，直到遍历所有的入边。
3. 从name属性值为"Europe"的顶点开始执行同样的操作，并建立顶点集in_europee。
4. 对于in_usa集合中的每个顶点，按照入边born_in来查找出生在美国境内某个地方的人。
5. 类似地，对于in_europe集合中的每个顶点，按照入边lives_in来查找居住在欧洲的人。
6. 最后，通过join把在美国出生的人的集合与在欧洲居住的人的集合相交。

​	如果相同的查询可以用一种查询语言写4行代码完成，而另一种查询语言则需要29行代码，这足以说明不同的数据模型适用于不同的场景。因此，选择适合应用程序的数据模型非常重要。

### 三元存储与SPARQL

> [数据模型和查询语言 -- 图形数据模型及本章概要 - 简书 (jianshu.com)](https://www.jianshu.com/p/9461022cbb22)

​	三元存储模式几乎等同于属性图模型，只是使用不同的名词描述了相同的思想。尽管如此，考虑到有多种针对三元存储的工具和语言，它们可能是构建应用程序宝贵的补充，因此还是值得在此讨论。

​	在三元存储中，所有信息都以非常简单的三部分形式存储(主体，谓语，客体)。例如，在三元组(吉姆，喜欢，香蕉)中，吉姆是主体，喜欢是谓语(动词)，香蕉是客体。

​	三元组的主体相当于图中的顶点。而客体则是以下两种之一:

1. 原始数据类型中的值，如字符串或数字。在这种情况下，三元组的谓语和客体分别相当于主体(顶点)属性中的键和值。例如，(lucy，age，33)就好比是顶点lucy，具有属性{"age":33}。
2. 图中的另一个顶点。此时，谓语是图中的边，主体是尾部顶点，而客体是头部顶点。例如，在(luey， marriedTo， alain)中，主体lucy和客体 alain都是顶点，并且谓语marriedTo是连接二者的边的标签。

#### 语义网

#### RDF数据模型

#### SPARQL查询语言

> 图数据库与网络模型的比较
>
> 在前面的“文档数据库是否在重演历史”中，我们介绍了 CODASYL 与关系模型如何竞争解决IMS中的多对多关系问题。乍一看， CODASYL 的网络模型和图模型很相似，那么图形数据库是乔装打扮的另一个 CODASYL吗?
>
> 答案是否定的，它们在以下几个重要方面有着明显区别：
>
> + 在 CODASY L中，数据库有一个模式来指定哪种记录类型可以嵌套在其他记录类型中。在图数据库中，则没有这样的限制：任何顶点都可以有边连接其他任何顶点。这就为应用程序适应不断变化的需求提供了更大的灵活性。
> + **在 CODASYL中，获取特定记录的唯一方法是遍历其中的一条访问路径。在图数据库中，则可以通过顶点的唯一ID直接引用该顶点，也可以使用索引查找满足特定值的那些顶点**。
> + 在 CODASYL中，记录的子记录是有序集合，所以数据库必须保持这种排序(这会对存储布局产生影响)，当应用插入新记录时不得不考虑新记录在这些集合中的位置。**在图数据库中，顶点和边不是有序的(只能在查询时对结果进行排序)。**
> + 在 CODASYL中，所有的查询都是命令式的，难以编写，并且很容易被模式的变化所破坏。在图数据库中，可以采用命令式代码来实现自己的遍历，但**大多数图形数据库还支持高级声明式查询语言**，例如 Cypher或SPARQL。

### Datalog基础

​	Datalog是比SPARQL或 Cypher更为古老的语言，在20世纪80年代被学者广泛研究。虽然在软件工程师中知名度较低，但它为以后的查询语言奠定了基础，因此它非常重要。

​	实践中有几个数据库系统采用了 Datalog。例如它是Datomic系统的查询语言，而Cascalog是用于查询Hadoop数据集的Datalog实现。

​	Datalog的数据模型类似于三元存储模式，但更为通用一些。它采用“谓语(主体客体)”的表达方式而不是三元组(主体，谓语，客体)。

​	Datalog方法需要釆取与其他査询语言略有不同的思维方式，但它非常强大，特别是规则可以在不同的查询中组合和重用。对于简单的一次性查询来说，这或许不太方便，但是如果数据非常复杂，处理起来会更加游刃有余。

## 2.4 小结

​	历史上，数据最初被表示为一棵大树(层次模型)，但是这不利于表示多对多关系，所以发明了关系模型来解决这个问题。最近，开发人员发现一些应用程序也不太适合关系模型。新的非关系“ NOSQL”数据存储在两个主要方向上存在分歧：

1. 文档数据库的目标用例是数据来自于自包含文档，且一个文档与其他文档之间的关联很少。
2. 图数据库则针对相反的场景，目标用例是所有数据都可能会互相关联。

​	**所有这三种模型(文档模型、关系模型和图模型)，如今都有广泛使用，并且在各自的目标领域都足够优秀。我们观察到，一个模型可以用另一个模型来模拟**。例如，图数据可以在关系数据库中表示，虽然处理起来比较笨拙。这就是为什么不同的系统用于不同的目的，而不是一个万能的解决方案。

​	**文档数据库和图数据库有一个共同点，那就是它们通常不会对存储的数据强加某个模式，这可以使应用程序更容易适应不断变化的需求**。<u>但是，应用程序很可能仍然假定数据具有一定的结构，只不过是模式是显式(写时强制)还是隐式(读时处理)的问题</u>。

​	毎个数据模型都有自己的查询语言或框架，我们讨论了几个例子：SQL、MapReduce、 MongoDB的聚合管道、 Cypher、SPARQLA和 Datalog。我们还讨论了CSS和XSL/ XPath，它们并不属于数据库查询语言，但存在有趣的相似之处。

​	虽然已经覆盖了很广的范围，但仍然有一些数据模型尚未提及。举几个简单的例子：

+ 使用基因组数据的硏究人员经常需要执行序列相似性搜索，这意味着需要用一个非常长的字符串(代表一个DNA分子)，与存在相似但却不完全相同的大型字符串数据库进行匹配。以上介绍的所有数据库都不适用于这种场景，这就是为什么研究人员开发了专门的基因组数据库软件，如 GenBank。
+ 数十年来，粒子物理学家一直在进行海量数据的超大规模数据分析，像大型强子对撞机(LHC)这样的项目，现在可以处理数百PB级别的数据在这种规模下，需要一些定制解决方案来避免硬件成本失控。
+ 全文搜索可以说是一种经常与数据库一起使用的数据模型。信息检索是一个很大的专业课题，本书不会详细介绍，但是将在第3章和第三部分中介绍搜索索引相关内容。

本章暂时告一段路。在下一章中，我们将讨论在实现本章所描述的数据模型过程中有哪些重要的权衡设计

# 第3章 数据存储与检索

## * 3.1 数据库核心：数据结构

> 日志这个词通常指的是应用程序的运行输出日志，来记录发生了什么事情。在本书中，日志则是一个更为通用的含义，表示一个仅能追加的记录序列集合。它可能是人类不可读的，可能是二进制格式而只能被其他程序来读取。

​	为了高效地査找数据库中特定键的值，需要新的数椐结构：索引。在本章中，我们将介绍一些索引结构并对它们进行比较；它们背后的基本想法都是保留一些额外的元数据，这些元数据作为路标，帮助定位想要的数据。如果希望用几种不同的方式搜索相同的数据，在数据的不同部分，我们可能定义多种不同的索引。

​	索引是基于原始数据派生而来的额外数据结构。很多数据库允许单独添加和删除索引，而不影响数据库的内容，它只会影响查询性能。**维护额外的结构势必会引入开销，特别是在新数据写入时**。对于写入，它很难超过简单地追加文件方式的性能，因为那已经是最简单的写操作了。<u>由于每次写数据时，需要更新索引，因此任何类型的索引通常都会降低写的速度</u>。

​	这里涉及存储系统中重要的权衡设计：**适当的索引可以加速读取査询，但每个索引都会减慢写速度**。为此，默认情况下，数据库通常不会对所有内容进行索引，它需要应用开发人员或数据库管理员，基于对应用程序典型查询模式的了解，来手动选择索引。目的是为应用程序提供最有利加速的同时，避免引入过多不必要的开销。

### 3.1.2 哈希索引

​	首先我们以键-值数据的索引开始。key- value类型并不是唯一可以索引的数据，但它随处可见，而且是其他更复杂索引的基础构造模块。

​	假设数据存储全部采用追加式文件组成，那么最简单的索引策略就是：保存内存中的 hash map，把毎个键一一映射到数据文件中特定的字节偏移量，这样就可以找到每个值的位置。每当在文件中追加新的key- value对时，还要更新 hash map来反映刚刚写入数据的偏移量(包括插入新的键和更新已有的键)。当査找某个值时，使用 hash map来找到文件中的偏移量，即存储位置，然后读取其内容。

​	这听起来可能过于简单，但它的确是一个可行的方法。事实上，这就是 Bitcask(Riak中的默认存储引擎)所采用的核心做法。 <u>Bitcask可以提供高性能的读和写，只要所有的key可以放入内存(因为 hash map需要保存在内存中)。而 value数据量则可以超过内存大小，只需一次磁盘寻址，就可以将vaue从磁盘加载到内存。如果那部分数据文件已经在文件系统的缓存中，则读取根本不需要任何的磁盘IO</u>。

​	**像Bitcask这样的存储引擎非常适合毎个键的值频繁更新的场景**。例如，key可能是某个关于猫的视频URL， value是它播放的次数(每次有人单击播放按钮时就增加)。对于这种工作负载，有很多写操作，但是没有太多不同的key，即每个key都有大量的写操作，但将所有key保存在内存中是可行的。

![img](https://img-blog.csdnimg.cn/img_convert/f815758dbc2650ce115c3d6068d75da9.png)

​	如上所述，只追加到一个文件，那么如何避免最终用尽磁盘空间？<u>一个好的解决方案是将日志分解成一定大小的段，当文件达到一定大小时就关闭它，并将后续写入到新的段文件中。然后可以在这些段上执行压缩</u>。**压缩意味着在日志中丢弃重复的键，并且只保留每个键最近的更新**。

​	此外，由于压缩往往使得段更小(假设键在段内被覆盖多次)，**也可以在执行压缩的同时将多个段合并在一起**。**由于段在写入后不会再进行修改，所以合并的段会被写入另一个新的文件**。<u>对于这些冻结段的合并和压缩过程可以在后台线程中完成，而且运行时，仍然可以用旧的段文件继续正常读取和写请求。当合并过程完成后，将读取请求切换到新的合并段上，而旧的段文件可以安全删除</u>。

​	每个段现在都有自己的内存哈希表，将键映射到文件的偏移量。为了找到键的值，首先检査最新的段的 hash map；如果键不存在，检査第二最新的段，以此类推。由于合并过程可以维持较少的段数量，因此查找通常不需要检查很多 hash map。

![img](https://img-blog.csdnimg.cn/img_convert/3ca1cfb3cc197afd5d609921202de816.png)

![img](https://img-blog.csdnimg.cn/img_convert/871d5532fb3a91d3cfc3225741bb82b0.png)

​	还有很多细节方面的考虑才能使得这个简单的想法在实际中行之有效。简而言之，在真正地实现中有以下重要问题：

+ 文件格式

  CSⅤ不是日志的最佳格式。更快更简单的方法是使用二进制格式，首先以字节为单位来记录字符串的长度，之后跟上原始字符串(不需要转义)。

+ 删除记录

  **如果要删除键和它关联的值，则必须在数据文件中追加一个特殊的删除记录(有时候称为墓碑)。当合并日志段时，一旦发现墓碑标记，则会丢弃这个已删除键的所有值**。

+ 崩溃恢复

  如果数据库重新启动，则内存中的 hash map将丢失。原则上，可以通过从头到尾读取整个段文件，然后记录毎个键的最新值的偏移量，来恢复每个段的hash map。但是，如果分段文件很大，可能扫描需要很长时间，这将使服务器重启变得缓慢。 Bitcask通过将毎个段的 hash map的快照存储在磁盘上，可以更快地加载到内存中，以此加快恢复速度。

+ 部分写入的记录

  数据库随时可能崩溃，包括将记录追加到日志的过程中。 Bitcask文件包括**校验值**，这样可以发现损坏部分并丢弃。

+ 并发控制

  **由于写入以严格的先后顺序追加到日志中，通常的实现选择是只有一个写线程**。数据文件段是追加的，并且**是不可变的，所以他们可以被多个线程同时读取**。

​	一个追加的日志乍看起来似乎很浪费空间：为什么不原地更新文件，用新值覆盖旧值？但是，结果证明追加式的设计非常不错，主要原因有以下几个：

+ **追加和分段合并主要是顺序写，它通常比随机写入快得多，特别是在旋转式磁性硬盘上。在某种程度上，顺序写入在基于闪存的固态硬盘(solid state drives，SSD)上也是适合的**。我们将在本章后面的“比较B-tree和 LSM-trees”部分进步讨论此问题。
+ **<u>如果段文件是追加的或不可变的，则并发和崩溃恢复要简单得多。例如，不必担心在重写值时发生崩溃的情况，留下一个包含部分旧值和部分新值混杂在一起的文件</u>**。
+ **合并旧段可以避免随着时间的推移数据文件出现碎片化的问题**。

​	但是，哈希表索引也有其局限性：

+ 哈希表必须全部放入内存，所以如果有大量的键，就没那么幸运了。原则上，可以在磁盘上维护hash map，但不幸的是，很难使磁盘上的 hash map表现良好。<u>它需要大量的随机访问I/O，当哈希变满时，继续增长代价昂贵，并且哈希冲突时需要复杂的处理逻辑</u>。
+ 区间查询效率不高。例如，不能简单地支持扫描 kitty00000 和 kitty99999 区间内的所有键，只能采用逐个查找的方式查询每一个键。

​	在下一节中，我们将看到摆脱这些限制的其他索引结构。

### 3.1.3 SSTables和LSM-Tree

![ddia-fig3-4](https://img-blog.csdnimg.cn/img_convert/c511dcce0b84aff251a9ca3cabad0f2b.png)

![image.png](https://img-blog.csdnimg.cn/img_convert/306b6a5a131ba99faac02d88b26185b5.png)

​	在图3-3中，每个日志结构的存储段都是一组key-value对的序列。这些key-value对按照它们的写入顺序排列，并且对于出现在日志中的同一个键，后出现的值优于之前的值。除此之外，文件中key-vaue对的顺序并不重要。

​	现在简单地改变段文件的格式：要求key-value对的顺序按键排序。乍一看，这个要求似乎打破了顺序写规则，我们稍后会解释。

​	这种格式称为排序字符串表，或简称为SSTable。它要求每个键在每个合并的段文件中只能出现一次(压缩过程已经确保了)。 SSTable相比哈希索引的日志段，具有以下优点：

1. 合并段更加简单高效，即使文件大于可用内存。方法类似于合并排序算法中使用的方法，如图3-4所示。并发读取多个输入段文件，比较每个文件的第一个键，把最小的键(根据排序顺序)拷贝到输出文件，并重复这个过程。这会产生一个新的按键排序的合并段文件。如果相同的键出现在多个输入段怎么办？<u>请记住，每个段包含在某段时间内写入数据库的所有值。这意味着一个输入段中的所有值肯定比其他段中的所有值更新(假设总是合并相邻的段)。当多个段包含相同的键时，可以保留最新段的值，并丢弃旧段中的值。</u>
2. 在文件中查找特定的键时，不再需要在内存中保存所有键的索引。以图3-5为例，假设正在査找键 handiwork，且不知道该键在段文件中的确切偏移。但是，如果知道键 handbag和键 handsome的偏移量，考虑到根据键排序，则键handiwork一定位于它们两者之间。这意味着可以跳到handbag的偏移，从那里开始扫描，直到找到 handiwork(如果键 handiwork不存在文件中，那么找不到)。所以，仍然需要一个内存索引来记录某些键的偏移，但它可以是稀疏的，<u>由于可以很快扫描几千字节，对于段文件中毎几千字节，只需要一个键就足够了</u>。

3. 由于读请求往往需要扫描请求范围内的多个key-value对，可以考虑将这些记录保存到一个块中并在写磁盘之前将其压缩(如图3-5中阴影区域所示)。然后**稀疏内存索引**的毎个条目指向压缩块的开头。除了节省磁盘空间，压缩还减少了I/O带宽的占用。

#### 构建和维护SSTables

​	到目前为止，似乎一切还算顺利，但是，考虑到写入可能以任意顺序出现，首先该如何让数据按键排序呢？

​	在磁盘上维护排序结构是可行的(参阅本章后面的“B- trees”)，不过，将其保存在内存中更容易。**内存排序有很多广为人知的树状数据结构，例如红黑树或AVL树**。使用这些数据结构，可以按任意顺序插入键并以排序后的顺序读取它们。

​	存储引擎的基本工作流程如下：

+ 当写入时，将其添加到内存中的平衡树数据结构中(例如红黑树)。这个内存中的树有时被称为内存表。
+ **当内存表大于某个阈值(通常为几兆字节)时，将其作为 SSTable 文件写入磁盘**。由于树已经维护了按键排序的key-value对，写磁盘可以比较高效。新的SSTable文件成为数据库的最新部分。当 SSTable写磁盘的同时，写入可以继续添加到一个新的内存表实例。
+ **为了处理读请求，首先尝试在内存表中査找键，然后是最新的磁盘段文件，接下来是次新的磁盘段文件，以此类推，直到找到目标(或为空)**。
+ **后台进程周期性地执行段合并与压缩过程，以合并多个段文件，并丢弃那些已被覆盖或删除的值**。

​	上述方案可以很好地工作。但它还存在一个问题：<u>如果数据库崩溃，最近的写入(在内存表中但尚未写入磁盘)将会丢失。为了避免该问题，可以在磁盘上保留单独的日志，每个写入都会立即追加到该日志，就像上一节所述。那个日志文件不需要按键排序，这并不重要，因为它的唯一目的是在崩溃后恢复内存表</u>。每当将内存表写入SSTable时，相应的日志可以被丢弃。

#### 从SSTables到LSM-Tree

​	以上描述的算法本质上正是 LevelDB和 RocKsDB 所使用的，主要用于嵌入到其他应用程序的 key-value 存储引擎库。此外，在Riak中 LevelDB 可以用作 Bitcask 的替代品。类似的存储引擎还被用于 Cassandra 和 HBase，这两个引擎都受到 Google 的 Bigtable 论文的启发(它引入了 SSTable和内存表这两个术语)。

​	最初这个索引结构由 Patrick O‘Neil 等人以日志结构的合并树(Log-Structured MergeTree，或 LSM-tree)命名，它建立在更早期的日志结构文件系统之上。因此，**基于合并和压缩排序文件原理的存储引擎通常都被称为LSM存储引擎**。

​	Lucene 是 Elasticsearch 和 Solr 等全文搜索系统所使用的索引引擎，它采用了类似的方法来保存其词典。全文索引比 key-value素引复杂得多，但它基于类似的想法：给定搜索査询中的某个单词，找到提及该单词的所有文档(网页、产品描述等)。它主要采用key- value结构实现，其中**键是单词(词条)，值是所有包含该单词的文档ID的列表(倒排表)**。在 Lucene中，从词条到 posting list的映射关系保存在类 SSTable的排序文件中，这些文件可以根据需要在后台合并。

#### 性能优化

​	总是有很多细节值得深入优化，这样才能使存储引擎在实际中表现得更好。例如，当査找数据库中某个不存在的键时，LSM-Tree算法可能很慢：<u>在确定键不存在之前必须先检査内存表，然后将段一直回溯访问到最旧的段文件(可能必须从磁盘多次读取)</u>。为了优化这种访问，存储引擎通常使用额外的**布隆过滤器**(布隆过滤器是内存高效的数据结构，用于近似计算集合的内容。如果数据库中不存在某个键，它能够很快告诉你结果，从而节省了很多对于不存在的键的不必要的磁盘读取)。

​	还有不同的策略会影响甚至决定 SSTables 压缩和合并时的具体顺序和时机。最常见的方式是大小分级和分层压缩。 LevelDB 和 RocKsDB 使用**分层压缩**(因此名称为LevelDB)， HBase使用**大小分级**， Cassandra则同时支持这两种压缩。

+ 在大小分级的压缩中，较新的和较小的 SSTables 被连续合并到较旧和较大的 SSTables。
+ 在分层压缩中，键的范围分裂成多个更小的 SSTables，旧数据被移动到单独的“层级”，这样压缩可以逐步进行并节省磁盘空间。

​	即使有许多细微的差异，但LSM-tree的基本思想(保存在后台合并的一系列SSTable)却足够简单有效。即使数据集远远大于可用内存，它仍然能够正常工作。由于数据按排序存储，因此可以有效地执行区间查询(从最小值到最大值扫描所有的键)，并且由于磁盘是顺序写入的，所以 LSM-tree 可以支持非常高的写入吞吐量。

### 3.1.4 B-Trees

​	目前讨论的日志结构索引正在逐渐受到更多的认可，但它们还不是最常见的索引类型。最广泛使用的索引结构是另一种不同的：B-tree。

​	B-tree始见于1970年，不到十年便被冠以“普遍存在”，B-tree经受了长久的时间考验。时至今日，它仍然是几乎所有关系数据库中的标准索引实现，许多非关系型数据库也经常使用。<u>像 SSTable 一样，B-tree保留按键排序的key-value对，这样可以实现高效的key-vaue査找和区间查询</u>。但相似仅此而已：B-tree本质上具有非常不同的设计理念。

​	之前看到的日志结构索引将数据库分解为可变大小的段，通常大小为几兆字节或更大，并且始终按顺序写入段。相比之下，<u>B-tree将数据库分解成固定大小的块或页，传统上大小为4KB(有时更大)，页是内部读/写的最小单元</u>。这种设计更接近底层硬件，因为磁盘也是以固定大小的块排列。

​	每个页面都可以使用地址或位置进行标识，这样可以让一个页面引用另一个页面，类似指针，不过是指向磁盘地址，而不是内存。可以使用这些页面引用来构造一个树状页面，如图3-6所示。

​	某一页被指定为B-tree的根；每当查找索引中的一个键时，总是从这里开始。该页面包含若干个键和对子页的引用。每个孩子都负责一个连续范围内的键，相邻引用之间的键可以指示这些范围之间的边界。

![img](https://img-blog.csdnimg.cn/img_convert/f5c3d5a1c897fe74fd8ac84bad79be93.png)

​	在图3-6的例子中，假定正在查找键251，因此需要沿着200~300间的页引用，到达类似的页，它进一步将200~300范围分解成子范围。最终，我们到达一个包含单个键的页(叶子页)，该页包含每个内联键的值或包含可以找到值的页的引用。

​	B-tree中一个页所包含的子页引用数量称为分支因子。例如，在图3-6中，分支因子为6。在实际中，分支因素取决于存储页面引用和范围边界所需的空间总量，通常为几百个。

​	如果要更新 B-tree 中现有键的值，首先搜索包含该键的叶子页，更改该页的值，并将页写回到磁盘(对该页的任何引用仍然有效)。如果要添加新键，则需要找到其范围包含新键的页，并将其添加到该页。如果页中没有足够的可用空间来容纳新键，则将其分裂为两个半满的页，并且父页也需要更新以包含分裂之后的新的键范围，如图3-7所示。

![img](https://img-blog.csdnimg.cn/img_convert/bd80b93b547baccf71efc5bb8ecab601.png)

​	该算法确保树保持平衡：具有n个键的B-tree总是具有O(log n)的深度。大多数数据库可以适合3~4层的B-tree，因此不需要遍历非常深的页面层次即可找到所需的页(分支因子为500的4KB页的四级树可以存储高达256TB)。

#### 使B-tree可靠

​	<u>B-tree底层的基本写操作是使用新数据覆盖磁盘上的旧页</u>。它假设覆盖不会改变顶的磁盘存储位置，也就是说，当页被覆盖时，对该页的所有引用保持不变。这与日志结构索引(如 LSM-tree)形成鲜明对比，LSM-tree仅追加更新文件(并最终删除过时的文件)，但不会修改文件。

​	可以认为磁盘上的页覆盖写对应确定的硬件操作。在磁性硬盘驱动器上，这意味着将磁头首先移动到正确的位置，然后旋转盘面，最后用新的数捃覆盖相应的扇区。对于SSD，由于SSD必须一次擦除并重写非常大的存储芯片块，情况会更为复杂。

​	此外，<u>某些操作需要覆盖多个不同的页。例如，如果插入导致页溢出，因而需分裂页，那么需要写两个分裂的页，并且覆盖其父页以更新对两个子页的引用。这是个比较危险的操作，因为如果数据库在完成部分页写入之后发生崩溃，最终会导致索引破坏(例如，可能有一个孤儿页，没有被任何其他页所指向)</u>。

​	**为了使数据库能从崩溃中恢复，常见B-tree的实现需要支持磁盘上的额外的数据结构：预写日志(write-ahead log，WAL)，也称为重做日志**。这是一个仅支持追加修改的文件，<u>每个B-tree的修改必须先更新WAL然后再修改树本身的页。当数据库在崩溃后需要恢复时，该日志用于将B-tree恢复到最近一致的状态</u>。

​	**原地更新页的另一个复杂因素是，如果多个线程要同时访问B-tree，则需要注意并发控制，否则线程可能会看到树处于不一致的状态**。<u>通常使用锁存器(轻量级的锁)保护树的数据结构来完成</u>。在这方面，日志结构化的方法显得更简单，因为它们在后台执行所有合并，而不会干扰前端的查询，并且会不时地用新段**原子**地替换旧段。

#### 优化B-Tree

​	由于B-tree已经存在了很长时间，自然多年来开发了许多优化措施。这里只列举一些：

+ 一些数据库(如LMDB)不使用覆盖页和维护WAL来进行崩溃恢复，而是使用**写时复制**方案。<u>修改的页被写入不同的位置，树中父页的新版本被创建，并指向新的位置</u>。这种方法对于并发控制也很有帮助，详见后面第7章“快照隔离与可重复读”。
+ 保存键的缩略信息，而不是完整的键，这样可以节省页空间。特别是在树中间的页中，只需要提供足够的信息来描述键的起止范围。这样可以将更多的键压入到页中，让树具有更高的分支因子，从而<u>减少层数</u>。
+ 一般来说，页可以放在磁盘上的任何位置；没有要求相邻的页需要放在磁盘的相邻位置。如果査询需要按照顺序扫描大段的键范围，考虑到毎个读取的页都可能需要磁盘I/O，所以逐页的布局可能是低效的。因此，许多B-tree的实现尝试对树进行布局，以便相邻叶子页可以按顺序保存在磁盘上。然而，随着树的增长，维持这个顺序会变得越来越困难。相比之下，由于LSM-tree在合并过程中一次重写大量存储段，因此它们更容易让连续的键在磁盘上相互靠近。
+ 添加额外的指针到树中。例如，每个叶子页面可能会向左和向右引用其同级的兄弟页，这样可以顺序扫描键，而不用跳回到父页。
+ B-tree变体如分形树，借鉴了一些日志结构的想法来减少磁盘寻道(与分形无关)。

### 3.1.5 对比B-tree和LSM-tree

​	尽管B-tree的实现比LSM-tree的实现更为成熟，然而由于LSM-tree的性能特点，LSM-tree目前很有吸引力。**根据经验，LSM-tree通常对于写入更快，而B-tree被认为对于读取更快**。读取通常在 LSM-tree上较慢，因为它们必须在不同的压缩阶段检查多个不同的数据结构和SSTable。

​	然而，基准测试通常并不太确定，而且取决于很多工作负载的具体细节。最好测试特定工作负载，这样方便进行更有效的比较。在本节中，将简要讨论在测量存储引擎性能时值得考虑的一些要点。

#### LSM-tree的优点

​	**B-tree索引必须至少写两次数据：一次写入预写日志，一次写入树的页本身(还可能发生页分裂)**。即使该页中只有几个字节更改，也必须承受写整个页的开销。一些存储引擎甚至覆盖相同的页两次，以避免在电源故障的情况下最终出现部分更新的页。

​	**由于反复压缩和SSTable的合并，日志结构索引也会重写数据多次**。这种影响(在数据库内，由于一次数据库写入请求导致的多次磁盘写)称为**写放大**。对于SSD，由于只能承受有限次地擦除覆盖，因此尤为关注写放大指标。

​	对于大量写密集的应用程序，性能瓶颈很可能在于数据库写入磁盘的速率。在这种情况下，写放大具有直接的性能成本：<u>存储引擎写入磁盘的次数越多，可用磁盘带宽中每秒可以处理的写入越少</u>。

​	此外，LSM-tree通常能够承受比B-tree更高的写入吞吐量，部分是因为它们有时具有较低的写放大(尽管这取决于存储引擎的配置和工作负载)，部分原因是它们以顺序方式写入紧凑的 SSTable文件，而不必重写树中的多个页。这种差异对于磁盘驱动器尤为重要，原因是**磁盘的顺序写比随机写要快得多**。

​	LSM-tree可以支持更好地压缩，因此通常磁盘上的文件比B-tree小很多。由于碎片，B-tree存储引擎使某些磁盘空间无法使用：当页被分裂或当一行的内容不能适合现有页时，页中的某些空间无法使用。由于 LSM-tree不是面向页的，并且定期重写SSTables以消除碎片化，所以它们具有较低的存储开销，特别是在使用分层压缩时。

​	在许多SSD上，固件内部使用日志结构化算法将随机写入转换为底层存储芯片上的顺序写入，所以存储引擎写入模式的影响不那么明显。然而，更低的写放大和碎片减少对于SSD上仍然有益，以更紧凑的方式表示数据，从而在可用的I/O带宽中支持更多的读写请求。

#### LSM-tree的缺点

​	日志结构存储的缺点是**压缩过程有时会干扰正在进行的读写操作**。即使存储引擎尝试增量地执行压缩，并且不影响并发访问，但由于磁盘的并发资源有限，所以当磁盘执行昂贵的压缩操作时，很容易发生读写请求等待的情况。这对吞吐量和平均响应时间的影响通常很小，但是如果观察较高的百分位数(参看第1章“描述性能”)日志结构化存储引擎的査询响应时间有时会相当高，而B-tree的响应延迟则更具确定性。

​	**高写入吞吐量时，压缩的另一个问题就会冒出来：磁盘的有限写入带宽需要在初始写入(记录并刷新内存表到磁盘)和后台运行的压缩线程之间所共享**。写入空数据库时，全部的磁盘带宽可用于初始写入，但数据库的数据量越大，压缩所需的磁盘带宽就越多。

​	**如果写入吞吐量很高并且压缩没有仔细配置，那么就会发生压缩无法匹配新数据写入速率的情况。在这种情况下，磁盘上未合并段的数量不断增加，直到磁盘空间不足，<u>由于它们需要检查更多的段文件，因此读取速度也会降低</u>**。<u>通常，即使压缩不能跟上，基于SSTable的存储引擎也不会限制到来的写入速率，因此需要额外的监控措施来及时发现这种情况</u>。

​	B-tree的优点则是每个键都恰好唯一对应于索引中的某个位置，而日志结构的存储引擎可能在不同的段中具有相同键的多个副本。<u>如果数据库希望提供强大的事务语义，这方面B-tree显得更具有吸引力：**在许多关系数据库中，事务隔离是通过键范围上的锁来实现的**</u>，并且在B-tree索引中，这些锁可以直接定义到树中。在第7章，我们将更详细地讨论这一点。

​	B-tree在数据库架构中已经根深蒂固，为许多工作负载提供了一贯良好的性能，所以不太可能在短期內会消失。对于新的数据存储，日志结构索引则越来越受欢迎。不存在快速和简单的规则来确定哪种存储引擎更适合你的用例，因此，实地的测试总是需要的。

### 3.1.6 其他索引结构

​	到目前为止，只讨论了key-value索引，它们像关系模型中的主键(primary key)索引。主键唯一标识关系表中的一行，或文档数据库中的一个文档，或图形数据库中的一个顶点。数据库中的其他记录可以通过其主键(或ID)来引用该行/文档/顶点，该索引用于解析此类引用。

​	**二级索引**也很常见。在关系数据库中，可以使用CREATE INDEX命令在同一个表上创建多个二级索引，并且它们通常对于高效地执行联结操作至关重要。

​	二级索引可以容易地基于key-value索引来构建。主要区别在于它的键不是唯一的，即可能有许多行(文档，顶点)具有相同键。这可以通过两种方式解决：使索引中的每个值成为匹配行标识符的列表(像全文索引中的 posting list)，或者追加一些行标识符来使每个键变得唯一。无论哪种方式，B-tree和日志结构索引都可以用作二级索引。

#### 在索引中存储值

> [mysql变长类型字段varchar值更新变长或变短底层文件存储原理 - 月光冷锋 - 博客园 (cnblogs.com)](https://www.cnblogs.com/liuche/p/15595129.html)
>
> [mysql覆盖索引与回表 - 简书 (jianshu.com)](https://www.jianshu.com/p/8991cbca3854)

​	索引中的键是查询搜索的对象，而值则可以是以下两类之一：它可能是上述的实际行(文档，顶点)，也可以是对其他地方存储的行的引用。在后一种情况下，存储行的具体位置被称为**堆文件**，并且它不以特定的顺序存储数据(它可以是追加的，或者记录删掉的行以便用新数据在之后覆盖它们)。<u>堆文件方法比较常见，这样当存在多个级索引时，它可以避免复制数据，即每个索引只引用堆文件中的位置信息，实际数据仍保存在一个位置</u>。

​	**当更新值而不更改键时，堆文件方法会非常高效：只要新值的字节数不大于旧值，记录就可以直接覆盖。如果新值较大，则情况会更复杂，它可能需要移动数据以得到一个足够大空间的新位置。在这种情况下，<u>所有索引都需要更新以指向记录的新的堆位置，或者在旧堆位置保留一个间接指针</u>**。

​	在某些情况下，从索引到堆文件的额外跳转对于读取来说意味着太多的性能损失，因此可能希望将索引行直接存储在索引中。这被称为聚集索引。例如，**在 MySQL的Innodb存储引擎中，表的主键始终是聚集索引**，<u>二级索引引用主键(而不是堆文件位置)</u>。在 SQL Server中，可以为每个表指定一个聚集索引。

​	**聚集索引(在索引中直接保存行数据)**和**非聚集索引(仅存储索引中的数据的引用)**之间有一种折中设计称为**覆盖索引**或包含列的索引，它在索引中保存一些表的列值。它可以支持只通过索引即可回答某些简单查询(在这种情况下，称索引覆盖了查询)。

​	与任何类型的数据冗余一样，聚集和覆盖索引可以加快读取速度，但是它们需要额外的存储，并且会增加写入的开销。此外，数据库还需要更多的工作来保证事务性，这样应用程序不会因为数据冗余而得到不一致的结果。

#### 多列索引

​	迄今为止讨论的索引只将一个键映射到一个值。如果需要同时查询表的多个列(或文档中的多个字段)，那么这是不够的。

​	最常见的多列索引类型称为级联索引，它通过将一列追加到另一列，将几个字段简单地组合成一个键(索引的定义指定字段连接的顺序)。这就像一个老式的纸质电话簿，它提供从(lastname， firstname)到电话号码的索引。<u>由于排序，索引可用于查找具有特定 last name的所有人，或所有具有特定 lastname-firstname 组合的人。但是，它无法查找具有特定 first name的所有人。</u>

​	多维索引是更普遍的一次查询多列的方法，这对地理空间数据尤为重要。例如，餐馆搜索网站可能有一个包含毎个餐厅的纬度和经度的数据库。当用户在地图上查看餐馆时，网站需要搜索用户正在查看的矩形地图区域内的所有餐馆。这要求一个二维的范围查询，如下所示：

```sql
SELECT * FROM restaurants WHERE latitude > 51.4946 AND latitude < 51.5079
AND longitude > -0.1162 AND longitude < -0.1004; 
```

​	标准B-tree或LSM-tree索引无法高效地应对这种查询，它只能提供一个纬度范围内(但在任何经度)的所有餐馆，或者所有经度范围内的餐厅(在北极和南极之间的任何地方)，但不能同时满足。

​	一种选择是使用空格填充曲线将二维位置转换为单个数字，然后使用常规的B-tree索引。更常见的是使用专门的空间索引，如R树。例如， PostGIS使用 PostgreSQL的广义搜索树索引实现了地理空间索引作为R树。篇幅所限，这里无法详细描述R树，但有很多关于它们的参考文献。

​	一个有趣的想法是，多维索引不仅仅适用于地理位置。例如，在电子商务网站上，可以使用颜色维度(红色，绿色，蓝色)上的三维索引来搜索特定颜色范围内的产品，或在天气观测数据库中，可以在(日期，温度)上创建二维索引，以便高效地搜索在2013年中，温度在25~30°C之间的所有观测值。使用一维索引，将不得不从2013年扫描所有记录(无论温度如何)，然后按温度进行过滤，反之亦然。二维索引可以通过时间戳和温度同时缩小查询范围。 HyperDex使用了这种技术。

#### 全文搜索和模糊索引

​	到目前为止讨论的所有索引都假定具有确切的数据，并允许査询键的确切值或排序的键的取值范围。它们不支持搜索类似的键，如拼写错误的单词。这种模糊查询需要不同的技术。

​	例如，全文搜索引擎通常支持对一个单词的所有同义词进行查询，并忽略单词语法上的变体，在同一文档中搜索彼此接近的单词的出现，并且支持多种依赖语言分析的其他高级功能。为了处理文档或査询中的拼写错误， Lucene能够在某个编辑距离内搜索文本(编辑距离为1表示已经添加、删除或替换了一个字母)。

​	如上节“从SSTable到LSM-tree”所述， Lucene对其词典使用类似SSTable的结构。此结构需要一个小的内存索引来告诉查询，为了找到一个键，需要排序文件中的哪个偏移量。在LevelDB中，这个内存中的索引是一些键的稀疏集合，但是<u>在Lucene中，内存中的索引是键中的字符序列的有限状态自动机，类似字典树</u>。这个自动机可以转换成Levenshtein自动机，它支持在给定编辑距离内高效地搜索单词。

​	其他模糊搜索技术则沿着文档分类和机器学习的方向发展。有关更多细节，请参阅相关信息检索教程。

#### 在内存中保存所有内容

​	本章迄今为止讨论的数据结构都是为了适应磁盘限制。与内存相比，磁盘更难以处理。使用磁盘和SSD，如果要获得良好的读写性能，需要精心地安排磁盘上的数据布局。然而这些工作是值得的，因为磁盘有两个显著的优点：数据保存持久化(如果电源关闭，内容不会丢失)，并且每GB容量的成本比内存低很多。

​	随着内存变得更便宜，毎GB成夲被摊薄。而许多数据集不是那么大，可以将它们完全保留在内存中，或者分布在台机器上。这推动了内存数据库的发展。

​	一些内存中的key-value存储(如Memcached)，主要用于缓存，如果机器重启造成的数据丟失是可以接受的。但是其他内存数据库旨在实现持久性，例如可以通过用特殊硬件(如电池供电的内存)，或者通过将更改记录写入磁盘，或者将定期快照写入磁盘，以及复制内存中的状态到其他机器等方式来实现。

​	当内存数据库重启时，它需要重新载入其状态，无论是从磁盘还是通过网络从副本(除非使用特殊硬件)。尽管写入磁盘，但磁盘仅仅用作为了持久性目的的追加日志，读取完全靠内存服务。此外，写入磁盘还具有一些运维方面优势：磁盘上的文件可以容易地通过外部工具来执行备份、检杳和分析。

​	诸如VoltDB、MemSQL和Oracle TimesTen的产品是具有关系模型的内存数据库，相关供应商声称通过移除所有与管理磁盘数据结构相关的开销，它们可以获得极大的性能提升。 RAMCloud是一个开源的、具有持久性的内存key-value存储(对内存和磁盘上的数据使用日志结构)。而Redis和Couchbase通过异步写入磁盘提供较弱的持久性。

​	**与直觉相反，内存数据库的性能优势并不是因为它们不需要从磁盘读取**。<u>如果有足够的内存，即使是基于磁盘的存储引擎，也可能永远不需要从磁盘读取，因为操作系统将最近使用的磁盘块缓存在内存中。相反，内存数据库可以更快，是因为**它们避免使用写磁盘的格式对内存数据结构编码的开销**</u>。

​	除了性能外，内存数据库的另一个有意思的地方是，它提供了基于磁盘索引难以实现的某些数据模型。例如， Redis为各种数据结构(如优先级队列和集合)都提供了类似数据库的访问接口。由于所有的数据都保存在内存中，所以实现可以比较简单。

​	<u>最近的研究表明，内存数据库架构可以扩展到支持远大于可用内存的数据集，而不会导致以磁盘为中心架构的开销</u>。**所谓的反缓存方法，当没有足够的内存时，通过将最近最少使用的数据从內存写到磁盘，并在将来再次被访问时将其加载到内存。<u>这与操作系统对虚拟内存和交换文件的操作类似</u>，但数据库可以在记录级别而不是整个内存页的粒度工作，因而比操作系统更有效地管理内存**。不过，这种方法仍然需要索引完全放入内存(如本章开头的 Bitcask示例)。

​	如果将来**非易失性存储(non-volatile memory，NVM)**技术得到更广泛普及，可能还需要进一步改变存储引擎设计。目前这是一个新的研究领域，但值得密切关注。

> [非易失内存(NVM)在云上有哪些应用? - 知乎 (zhihu.com)](https://www.zhihu.com/question/390009101/answer/1180400821)

## 3.2 事务处理与分析处理

​	在商业数据处理的早期阶段，写入数据库通常对应于商业交易场景，例如销售、订单、支付员工工资等。尽管后来数据库扩展到了不涉及金钱交易的领域，事务一词仍然存在，主要指组成一个逻辑单元的一组读写操作。

> <u>事务不一定具有ACID(原子性、一致性、隔离性和持久性)属性</u>。**事务处理只是意味着允许客户端进行低延迟读取和写入，相比于只能周期性地运行(如每天一次)的批处理作业**。我们将在第7章讨论ACID属性，在第10章讨论批处理。

​	尽管数据库开始被用于许多不同种类的数据，例如博客的评论、游戏中的动作、通讯录中的联系人等，然而其基本访问模式仍然与处理业务交易类似。应用程序通常使用索引中的某些键査找少量记录。根据用户的输入插入或更新记录。因为这些应用程序是交互式的，所以访问模式被称为**在线事务处理(online transaction processing，OLTP)**。

​	然而，数据库也开始越来越多地用于数据分析，数据分析具有非常不同的访问模式。通常，分析査询需要扫描大量记录，每个记录只读取少数几列，并计算汇总统计信息(如计数、求和或平均值)，而不是返回原始数据给用户。例如，如果数据是销售交易表，那么分析查询可能包括：

+ 一月份每个店铺的总收入是多少？
+ 在最近促销的期间，比平时多卖了多少香蕉？
+ 哪个品牌的婴儿食品最常与某品牌的尿布一起购买？

​	这些查询通常由业务分析师编写，以形成有助于公司管理层更好决策(商业智能)的报告。为了区分使用数据库与事务处理的模式，称之为**在线分析处理(online analytic processing，OLAP)**。OLTP和OLAP之间的区别有时并不那么明确，它们的些典型的特性总结见表3-1。

表3-1：对比事务处理与分析系统的主要特性

| 属性         | 事务处理系统（OLTP）           | 分析系统（OLAP）             |
| ------------ | ------------------------------ | ---------------------------- |
| 主要读特征   | 基于键，每次查询返回少量的记录 | 对大量记录进行汇总           |
| 主要写特征   | 随机访问，低延迟写入用户的输入 | 批量导入（ETL）或事件流      |
| 典型实用场景 | 终端用户，通过网络应用程序     | 内部分析师，为决策提供支持   |
| 数据表征     | 最新的数据状态（当前时间点）   | 随着时间而变化的所有事件历史 |
| 数据规模     | GT到TB                         | TB到PB                       |

​	最初，相同的数据库可以同时用于事务处理和分析查询。在这方面，SQL被证明是非常灵活的，可以同时胜任OLTP类型和OLAP类型查询。然而，在20世纪80年代后期和90年代初期的一种趋势是，公司放弃使用OLTP系统用于分析目的，而是在单独的数据库上运行分析。这个单独的数据库被称为数据仓库。

### * 3.2.1 数据仓库

​	企业可能有几十种不同的交易处理系统，例如面向客户的网站提供支持的系统、控制实体店的销售(结账)系统、跟踪仓库库存、为车辆规划路线、供应商管理、员工管理等。这些系统中的每一个都足够复杂，往往需要一个专门团队来维护，最终导致这些系统彼此独立运行。

​	由于这些OLTP系统对于业务的运行至关重要，所以往往期望它们高度可用，处理事务时延迟足够低，并且数据库管理员要密切关注OLTP数据库运行状态。数据库管理员通常不愿意让业务分析人员在OLTP数据库上直接运行临时分析查询，这些查询通常代价很高，要扫描大量数据集，这可能会损害并发执行事务的性能。

​	相比之下，数据仓库则是单独的数据库，分析人员可以在不影响OLTP操作的情况下尽情地使用。<u>数据仓库包含公司所有各种OLTP系统的只读副本</u>。从OLTP数据库(使用周期性数据转储或连续更新流)中提取数据，转换为分析友好的模式，执行必要的清理，然后加载到数据仓库中。**将数据导入数据仓库的过程称为提取-转换-加载(Extract-Transform-Load，ETL)**。

​	几乎所有的大型企业都有数据仓库，但是在小型企业中却几乎闻所未闻。这可能是因为大多数小公司没有那么多不同的OLTP系统，大多数小公司只拥有少量的数据，完全可以在传统的SQL数据库中直接进行査询分析，甚至可以在电子表格中进行分析。对于大公司，需要做大量繁重的工作来完成在小公司看似很简单的一些事情。

​	使用单独的数据仓库而不是直接查询OLTP系统进行分析，很大的优势在于数据仓库可以针对分析访问模式进行优化。<u>事实证明，本章前半部分讨论的索引算法适合OLTP，但不擅长应对分析查询</u>。

​	在本章的其余部分，将重点讨论针对分析型而优化的存储引擎。

#### OLTP数据库和数据仓库之间的差异

​	数据仓库的数据模型最常见的是关系型，因为SQL通常适合分析査询。有许多图形化数据分析工具，它们可以生成SQL査询、可视化结果并支持分析师探索数据，例如通过诸如向下钻取、切片和切丁等操作。

​	表面上，数据仓库和关系型OLTP数据库看起来相似，因为它们都具有SQL查询接口。然而，系统内部实则差异很大，它们针对迥然不同的查询模式进行了各自优化。许多数据库供应商现在专注于支持事务处理或分析工作负载，但不能同时支持两者。

​	一些数据库(如 Microsoft SQL Server和 SAP HANA)在同一产品中支持事务处理和数据仓库。然而，它们越来越成为两个独立的存储和查询引擎，这些引擎恰好可以通过个通用的SQL界面进行访问。

​	诸如 Teradata、Ⅴerica、 SAP HANA和 ParAccel等数据仓库供应商，通过昂贵的商业许可来销售其系统。 Amazon RedShift是 ParAccel的托管版本。最近，还出现了大量开源的基于Hadoop的SQL项目，它们还比较年轻，但都试图与商业数据仓库系统展开竞争。包括Apache Hive、 Spark SQL、 Cloudera Impala、 Facebook Presto、 Apache Tajo和 Apache Drill。其中一些系统是基于Google Dremel而构建的。

#### 星型与雪花型分析模式

​	如第2章所述，根据不同的应用需求，事务处理领域广泛使用了多种不同数据模型。而另一方面，分析型业务的数据模型则要少得多。<u>许多数据仓库都相当公式化的使用了星型模式，也称为维度建模</u>。

​	图3-9所示的模式可用于零售数据仓库。模式的中心是一个所谓的事实表(在这个例子中，它被称为fact_sales)。<u>事实表的每一行表示在特定时间发生的事件(这里，每一行代表客户购买的一个产品)</u>。如果我们正在分析网站流量而不是零售，则每一行可能表示页面视图或用户的单击。

![img](https://pic4.zhimg.com/80/v2-3f2777efbb17420ae339191a974aea47_1440w.jpg)

​	通常，事实被捕获为单独的事件，这样之后的分析具有最大的灵活性。不过，这意味着事实表可能会变得非常庞大。像苹果、沃尔玛或者eBay这样的大企业，其数据仓库可能有数十PB的交易历史，其中大部分都保存在事实表中。

​	事实表中的列是属性，例如产品销售的价格和供应商处购买的成本(可以计算出利润率)。其他列可能会引用其他表的外键，称为维度表。由于事实表中的每一行都代表个事件，维度通常代表事件的对象(who)、什么(what)、地点(where)、时间(when)、方法(how)以及原因(why)。

​	例如，在图3-9中，其中一个维度是销售的产品。 dim_product表中的每一行代表一种出售的产品，包括库存单位(SKU)、说明、品牌名称、类别、脂肪含量、包装尺寸等。 fact_sales表中的每一行都使用外键来表示在该特定事务中出售的产品(简单起见，如果客户一次性购买了几种不同的产品，它们在事实表中被表示为单独的行)。

​	日期和时间通常使用维度表来表示，这样可以对日期(如公共假期)的相关信息进行编码，从而查询可以对比假期和非假日之间的销售情况。

​	<u>名称“星型模式”来源于当表关系可视化时，事实表位于中间，被一系列维度表包围；这些表的连接就像星星的光芒</u>。

​	该模板的一个变体称为雪花模式，其中维度进一步细分为子空间。例如，品牌和产品类别可能有单独的表格，在 dim_product 表中的每一行都可以再次引用品牌和类别作为外键，而不是将其作为字符串直接存储在 dim_product 表中。<u>雪花模式比星型模式更规范化，但是星型模式通常是首选，主要是因为对于分析人员，星型模式使用起来更简单</u>。

​	**在典型的数据仓库中，表通常非常宽：事实表通常超过100列，有时候有几百列。维度表也可能非常宽，可能包括与分析相关的所有元数据**，例如， dim_store 表可能包括很多详细信息，例如，哪个商店提供了哪些服务，店内是否有面包店、面积多大、商店开张的日期、最后一次装修日期、距离最近的公路有多远等。

## * 3.3 列式存储

​	如果事实表中有数以万亿行、PB大小的数据，则高效地存储和查询这些数据将成为个具有挑战性的问题。<u>维度表通常小得多(数百万行)，因此在本节中，将主要关注事实表的存储</u>。

​	**虽然事实表通常超过100列，但典型的数据仓库查询往往一次只访问其中的4或5个("SELECT *"查询很少用于分析)**。下面示例3-1中的查询中，它会访问大量行(某人在2013年中每一次购买水果或糖果)，但结果只需要返回 fact_sales表的三列：date_key、 product_sk 和 quantity，其他列不在输出范围。

示例3-1：分析人们购买新鲜水果或糖果的倾向是否取决于一周中的某天

```sql
SELECT
	dim_date.weekday, dim_product.category,
	SUM(fact_sales.quantity) AS quantity_sold
FROM fact_sales
	JOIN dim_date ON fact_sales.date_key = dim_date.date_key
	JOIN dim_product ON fact_sales.product_sk = dim_product.product_sk
WHERE
	dim_date.year = 2013 AND
	dim_product.category IN ('Fresh fruit', 'Candy')
GROUP BY
	dim_date.weekday, dim_product.category;
```

​	如何高效地执行这个查询？在大多数OLTP数据库中，存储以面向行的方式布局：来自表的一行的所有值彼此相邻存储。文档数据库也是类似，整个文档通常被存储为一个连续的字节序列。

​	为了处理像示例3-1这样的查询，可以在 fact_sales.date_key和fact_sales.product_sk上使用索引，告诉存储引擎在哪里査找特定日期或特定产品的所有销售。<u>但是，面向行的存储引擎仍然需要将所有行(每个由超过100个属性组成)从磁盘加载到内存中、解析它们，并过滤出不符合所需条件的行</u>。这可能需要很长时间。

​	**面向列存储的想法很简单：不要将一行中的所有值存储在一起，而是将每列中的所有值存储在一起**。如果每个列存储在一个单独的文件中，查询只需要读取和解析在该查询中使用的那些列，这可以节省大量的工作。

> 列存储在关系数据模型中最容易理解，但它同样适用于非关系数据。例如，Parquet是基于 Google的 Dremel的一种支持文档数据模型的列存储格式。

​	面向列的存储布局依赖一组列文件，每个文件以相同顺序保存着数据行。因此，如果需要重新组装整行，可以从每个单独的列文件中获取第23个条目，并将它们放在一起构成表的第23行。

### 3.3.1 列压缩

​	<u>除了仅从磁盘中加载査询所需的列之外，还可以通过压缩数据来进一步降低对磁盘吞吐量的要求。幸运的是，面向列的存储恰好非常适合压缩</u>。

​	看看图3-10中每列的值序列：它们看起来有很多重复，这是压缩的好兆头。取决于列中具体数据模式，可以采用不同的压缩技术。在数据仓库中特别有效的一种技术是**位图编码**，如图3-11所示。

![img](https://pic2.zhimg.com/80/v2-d559393ebde1e610def21001726ed0ed_1440w.jpg)

​	通常，列中的不同值的数量小于行数(一个例如，零售商可能拥有数十亿个销售交易，但只有100000个不同的产品)。现在可以**使用n个不同值的列，并将其转换为n个单独的位图：一个位图对应每个不同的值，一个位对应一行。如果行具有该值，该位为1，否则为0**。

​	**如果n非常小(例如，表示国家的列可能具有大约200个不同的值)，那么这些位图由毎行一位存储。但是，如果n越大，在大多数位图中将会有很多零(它们很稀疏)。此时，位图也可以进行游程编码**，如图3-11底部所示。这样列的编码非常紧凑。
​	这些**位图索引**非常适合在数据仓库中常见的查询。例如:

```sql
WHERE product_sk IN (30, 68, 69):
```

​	加载 product_sk = 30、 product_sk = 68 和 product_sk = 69 的三个位图，并计算三个位图的按位或，这可以非常高效地完成。

![img](https://pic2.zhimg.com/80/v2-b521a87c9bf8500ba1eb506f52ceb315_1440w.jpg)

```sql
WHERE product_sk = 31 AND store_sk = 3:
```

​	<u>加载 product sk=31和 store_sk=3的位图，并按位与计算。这样做也是可行的，这是因为**这些列包含相同顺序的行，因此一列的位图中的第k位对应于另列的位图中与第k位相同的行**</u>。

​	对于不同类型的数据，还有各种其他压缩方法。

> 面向列的存储和列族
>
> Cassandra 和 HBase 有一个**列族**的概念，它们继承自 Google Bigtable。<u>但是，将它们称为面向列则非常令人误解：**在每个列族中，它们将一行中的所有列与行主键一起保存，并且不使用列压缩。因此， Bigtable模型仍然主要是面向行**</u>。

#### 内存带宽和矢量化处理

> [SIMD_百度百科 (baidu.com)](https://baike.baidu.com/item/SIMD/3412835?fr=aladdin)
>
> [矢量化_百度百科 (baidu.com)](https://baike.baidu.com/item/矢量化/465614?fr=aladdin)

​	<u>对于需要扫描数百万行的数据仓库査询，将数据从磁盘加载到内存的带宽是一大瓶颈</u>。然而，这还不是唯一的瓶颈。分析数据库的开发人员还要关心<u>如何高效地将内存的带宽用于CPU缓存</u>，避免分支错误预测和CPU指令处理流水线中的气泡，并利用现代CPU中的单指令多数据(SIMD)指令。

​	除了减少需要从磁盘加载的数据量之外，面向列的存储布局也有利于高效利用CPU周期。例如，査询引擎可以将一大块压缩列数据放入CPU的L1缓存中，并以紧凑循环(即没有函数调用)进行迭代。对于每个被处理的记录，CPU能够比基于很多函数调用和条件判断的代码更快地执行这种循环。<u>列压缩使得列中更多的行可以加载到L1缓存。诸如先前描述的按位AND和OR的运算符，可被设计成直接对这样的列压缩数据块进行操作。这种技术被称为**矢量化处理**</u>。

### 3.3.2 列存储中的排序

​	在列存储中，行的存储顺序并不太重要。最简单的是按插入顺序保存，这样插入一个新行只是追加到毎个列文件。也可以选择强制某个顺序，就像之前SSTable一样，并将其用作索引机制。

​	<u>但请注意，单独排序每列是没有意义的，如果这样的话就无法知道列中的某一项属于哪一行</u>。因为**知道某列中的第k项和另一列的第k项一定属于同一行，基于这种约定我们可以重建一行**。

​	相反，**即使数据是按列存储的，它也需要一次排序整行**。<u>数据库管理员可以基于常见查询的知识来选择要排序表的列。例如，如果查询经常以日期范围为目标，例如上个月，那么明智的做法是将date_key设置为第一个排序键。査询优化器只扫描上个月的行，这将比扫描所有行快得多</u>。

​	当第一列排序出现相同值时，可以指定第二列继续进行排序。例如，如果date_key是图3-10中的第一个排序键，然后可以指定 product_sk成为第二个排序键，这样同一天同一产品的所有销售在存储中被分组在一起。这有助于在某个日期范围内按产品进行分组或过滤的查询。

​	**排序的另一个优点是它可以帮助进一步压缩列**。如果主排序列上没有很多不同的值，那么在排序之后，它将出现一个非常长的序列，其中相同的值在一行中重复多次。<u>一个简单的游程编码，如图3-11中的位图那样，即使该表可能拥有数十亿行，也可以将其压缩到几千字节</u>。

​	**基于第一个排序键的压缩效果通常最好**。<u>第二个和第三个排序键会使情况更加复杂，也通常不会有太多相邻的重复值。排序优先级进一步下降的列基本上会呈现接近随机的顺序，因此通常无法压缩。但总体来讲，对前几列排序仍然可以获得不错的收益</u>。

#### 几种不同的排序

​	C-Store最早引入了一种改进想法，并被商业数据仓库 Vertica所采用。考虑到不同的查询会从不同的排序中获益，那么为什么不<u>以多种不同的方式存储相同的数据</u>呢？无论如何，数据需要复制到多台机器，这样在一台机器发生故障时，不会丢失数据。不妨<u>存储不同方式排序的冗余数据，以便在处理查询时，可以选择最适合特定查询模式的排序版本</u>。

​	面向列的存储具有多个排序顺序，这有些类似在面向行的存储中具有多个二级索引。但最大的区别是，

+ **面向行的存储将每一行都保存在一个位置(在堆文件或聚集索引中)，而二级索引只包含指向匹配行的指针**。
+ **而对于列存储，通常没有任何指向别处数据的指针，只有包含值的列**。

### 3.3.3 列存储的写操作

​	上述这些优化对于数据仓库很有意义，因为大多数负载由分析人员运行的大型只读查询组成。**面向列的存储、压缩和排序都非常有助于加速读取査询。但是，它们的缺点是让写入更加困难**。

​	像B-tree使用的原地更新方式，对于压缩的列是不可能的。如果在排序表的中间插入一行，那么很可能不得不重写所有的列文件。因为各行是由它们在列中的位置标志的，所以插入操作必须一致地更新所有列。

​	幸运的是，在本章前面已经看到了一个很好的解决方案LSM-tree。**<u>所有的写入首先进入内存存储区，将其添加到已排序的结构中，接着再准备写入磁盘</u>。内存中的存储是面向行还是面向列无关紧要。当累积了足够的写入时，它们将与磁盘上的列文件合并，并批量写入新文件**。本质上这正是 Vertica 所做的事情。

​	<u>执行查询时，需要检查磁盘上的列数据和内存中最近的写入，并结合这两者。而査询优化器可以对用户隐藏这些内部细节</u>。从数据分析师的角度来看，插入、更新或删除数据可以立即反映在随后的查询中。

### 3.3.4 聚合：数据立方体与物化视图

​	<u>未必毎个数据仓库都基于列存储，传统的面向行数据库以及其他一些架构也有使用。然而，对于临时分析査询，列存储性能要快得多，因此它正在迅速普及</u>。

​	数据仓库的另一个值得一提的是**物化聚合**。如前所述，数据仓库查询通常涉及聚合函数，例如SQL中的 COUNT、SUM、AVG、MIN或MAX。如果许多不同查询使用相同的聚合，毎次都处理原始数据将非常浪费。为什么不**缓存査询最常使用的一些计数或总和**呢?

​	创建这种缓存的一种方式是**物化视图**。在关系数据模型中，它通常被定义为标准(虚拟)视图：一个类似表的对象，其内容是一些查询的结果。不同的是，**物化视图是查询结果的实际副本，并被写到磁盘，而虚拟视图只是用于编写查询的快捷方式**。从虚拟视图中读取时，SQL引擎将其动态地扩展到视图的底层查询，然后处理扩展查询。

​	**当底层数据发生变化时，物化视图也需要随之更新，因为它是数据的非规范化副本**。<u>数据库可以自动执行，但这种更新方式会影响数据写入性能，这就是为什么在OLTP数据库中不经常使用物化视图的原因</u>。而对于大量读密集的数据仓库，物化视图则更有意义(它们是否能够真正地提高读性能还要取决于具体情况)。

​	物化视图常见的一种特殊情况称为**数据立方体**或**OLAP立方体**。它是由不同维度分组的聚合网格，如图3-12所示的例子。

![img](https://pic4.zhimg.com/80/v2-54d144279c67e88887fefd454417d88b_1440w.jpg)

​	想象一下，每个事实只包含两个维度表的外键，在图3-12中，它们是日期(datekey)和产品(product_sk)。现在绘制这样一个二维表，日期沿着一个轴，产品沿着另一个轴。每个单元格即是date-product组合的所有事实的属性(例如，net_price)的聚合(例如，SUM)。然后，可以沿着每一行或列应用聚合操作，得到一个减少一个维度的总和(按产品销售额而不管日期，或按日期的销售额而不管产品)。

​	一般来说，事实表的维度不止两个，例如在图3-9中有五个维度：日期、产品、商店、促销和客户。想象五维超立方体是什么样子有些困难，但是原理是类似的：每个单元格包含特定日期-产品-商店-促销-客户组合的销售值。然后可以沿着每个维度汇总这些值。

​	**物化数据立方体的优点是某些查询会非常快，主要是它们已被预先计算出来**。例如，如果想知道昨天毎个商店的总销售量，只需要直接查看对应维度的总和，而不需要扫描数百万行。

​	**缺点则是，数据立方体缺乏像査询原始数据那样的灵活性**。例如，因为价格不是其中的一个维度，所以没有办法直接计算成本超过100美元的物品所占销售的比重。因此，**大多数数据仓库都保留尽可能多的原始数据，仅当数据立方体可以对特定查询显著提升性能时，才会采用多维数据聚合**。

## 3.4 小结

​	本章我们简单介绍了数据库内部如何处理存储与检索。诸如，数据库存储新数据时会发生什么，以及之后查询数据时，数据库会做什么?

​	概括来讲，存储引擎分为两大类：针对**事务处理(OLTP)**优化的架构，以及针对**分析型(OLAP)**的优化架构。

​	它们典型的访问模式存在很大差异：

+ OLTP系统通常面向用户，这意味着它们可能收到大量的请求。为了处理负载，应用程序通常在毎个査询中只涉及少量的记录。应用程序基于某种键来请求记录，而存储引擎使用索引来査找所请求键的数据。**磁盘寻道时间往往是瓶颈**。
+ 由于不是直接面对最终用户，数据仓库和类似的分析型系统相对并不太广为人知，它们主要由业务分析师使用。处理的查询请求数目远低于OLTP系统，但每个査询通常要求非常苛刻，需要在短时间内扫描数百万条记录。**磁盘带宽(不是寻道时间)通常是瓶颈**，而面向列的存储对于这种工作负载成为日益流行的解决方案。

​	在OLTP方面，由两个主要流派的存储引擎:

+ **日志结构流派**，它只允许追加式更新文件和删除过时的文件，但不会修改已写入的文件。 Bitcask、 SSTables、LSM-tree、 LevelDB、 Cassandra、 HBase、 Lucene等属于此类。

+ **原地更新流派**，将磁盘视为可以覆盖的一组固定大小的页。B-tree是这一哲学的最典型代表，它已用于所有主要的关系数据库，以及大量的非关系数据库。

​	日志结构的存储引擎是一个相对较新的方案。其关键思想是系统地将磁盘上随机访问写入转为顺序写入，由于硬盘驱动器和SSD的性能特性，可以实现更高的写入吞吐量。

​	此外，简要介绍了一些更复杂的索引结构，以及为全内存而优化的数据库。

​	然后，从存储引擎的内部间接地探索了典型数据仓库的总体架构。由此说明为什么分析工作负载与OLTP如此不同：<u>当査询需要在大量行中顺序扫描时，索引的关联性就会显著降低。相反，最重要的是非常紧凑地编码数据，以尽量减少磁盘读取的数据量</u>。我们讨论了列存储如何帮助实现这一目标。

​	作为应用开发人员，掌握更多有关存储引擎內部的知识，可以更好地了解哪种工具最适合你的具体应用。如果还需要进一步调整数据库的可调参数，这些理解还可以帮助开发者正确评估调高或调低参数所带来的影响。

​	尽管本章不能让你成为某个特定存储引擎的调优专家，但希望帮你获得足够的知识与见解，以充分理解所选择的数据库。

# 第4章 数据编码与演化

​	应用程序不可避免地需要随时间而变化、调整。当新产品推出，或为了更好地理解用户需求，或商业环境发生变化时，就需要不断地添加或修改功能。在第1章中我们介绍了可演化的思想，提岀应该构建可适应变化的系统(参阅第1章“可演化性：易于改变”)。

​	在大多数情况下，更改应用程序功能时，也需要更改其存储的数据：可能需要捕获新的字段或记录类型，或者需要以新的方式呈现已有数据。

​	<u>第2章所讨论的数据模型有不同的方法来应对这种变化。关系数据库通常假设数据库中的所有数据都符合一种模式，尽管该模式可以改变(通过模式迁移，即 ALTER语句)，这样在任何一个给定时间点都只有一个有效的模式。相比之下，读时模式(“无模式”)数据库不强制执行模式，所以数据库包含了不同时间写入的新旧数据的混合体(参阅第2章“文档模型中的模式灵活性”)</u>。

​	当数据格式或模式发生变化时，经常需要对应用程序代码进行相应的调整(例如，向记录中添加新字段，然后应用程序代码开始读取和写入该字段)。然而，对于一个大型应用系统，代码更迭往往并非易事:

+ **对于服务器端应用程序，可能需要执行滚动升级(也被称为分阶段发布)，每次将新版本部署到少数几个节点，检查新版本是否正常运行，然后逐步在所有节点上升级新的代码。这样新版本部署无需服务暂停，从而支持更频繁的版本发布和更好的演化。**
+ **对于客户端应用程序，只能寄望于用户，然而他们在一段时间内可能不会马上安装更新**。

​	**这意味着新旧版本的代码，以及新旧数据格式，可能会同时在系统内共存。为了使系统继续顺利运行，需要保持双向的兼容性**：

+ 向后兼容

  较新的代码可以读取由旧代码编写的数据。

+ **向前兼容**

  **较旧的代码可以读取由新代码编写的数据**。

​	向后兼容通常不难实现：作为新代码的作者，清楚旧代码所编写的数据格式，因此可以比较明确地处理这些旧数据(如果需要，只需保留旧的代码来读取旧的数据)。向前兼容可能会比较棘手，它需要旧代码忽略新版本的代码所做的添加。

​	在本章中，将介绍多种编码数据的格式，包括JSON、XML、 Protocol Buffers、 Thrift和Avro。特别地，我们将讨论它们如何处理模式变化，以及如何支持新旧数据和新旧代码共存的系统。之后，还将讨论这些格式如何用于数据存储和通信场景，包括在web服务中，具象状态传输(Representational State Transfer，REST)和远程过程调用(remote procedure calls，RPC)以及消息传递系统，如actors和消息队列。

## 4.1 数据编码格式

​	程序通常使用(至少)两种不同的数据表示形式：

1. 在内存中，数据保存在对象、结构体、列表、数组、哈希表和树等结构中。这些数据结构针对CPU的高效访问和操作进行了优化(通常使用指针)。
2. **将数据写入文件或通过网络发送时，必须将其编码为某种自包含的字节序列(例如JSON文档)。由于指针对其他进程没有意义，所以这个字节序列表示看起来与内存中使用的数据结构大不一样**。

​	因此，在这两种表示之间需要进行类型的转化。从内存中的表示到字节序列的转化称为编码(或序列化等)，相反的过程称为解码(或解析，反序列化)。

> 术语冲突
>
> 不幸的是，序列化一词也用于事务处理(参看第7章)，且意义完全不同。为了避免在本书中产生冲突，尽管序列化可能是更常见的术语，我们仍坚持使用编码。

​	由于这是一个常见的问题，因此存在许多不同的库和编码格式可供选择。我们在此做一个简要概述。

### 4.1.1 语言特定的格式

​	许多编程语言都内置支持将内存中的对象编码为字节序列。例如，Java有java.io.Serializable，Ruby有Marshal，Python有pickle等。此外，还有许多第三方库，例如用于Java的Kryo。

​	这些编码库使用起来非常方便，它们只需要很少的额外代码即可保存或恢复内存中的对象。然而，这里也有一些深层次的问题：

+ <u>编码通常与特定的编程语言绑定在一起，而用另一种语言访问数据就非常困难。如果用这种编码方式存储或传输数据，可能在很长一段时间内须使用当前的编程语言，并且不能将系统与其他组织(可能使用不同的语言)的系统方便地集成在一起</u>。
+ 为了在相同的对象类型中恢复数据，解码过程需要能够实例化任意的类。这经常导致一些安全问题：**如果攻击者可以让应用程序解码任意的字节序列，那么它们可以实例化任意的类，这通常意味着，它们可以做些可怕的事情，比如远程执行任意代码**。
+ 在这些库中，**多版本数据通常是次要的**，主要目标是快速且简单地编码数据，所以它们经常忽略向前和向后兼容性等问题。
+ **效率(编码或解码花費的CPU时间，以及编码结构的大小)通常也是次要的**。例如，Java的内置序列化由于其糟糕的性能和臃肿的编码而广为诟病。

​	由于这些原因，**使用语言内置的编码方案通常不是个好主意**，除非只是为了临时尝试。

### * 4.1.2 JSON 、XML 与二进制变体

​	目标转向可由不同编程语言编写和读取的标准化编码，显然JSON和XML是其中佼佼者。它们广为人知，得到广泛的支持，以及同样广泛的批评。XML经常被批评过于冗长和不必要的复杂。JSON受欢迎主要是由于它在Web浏览器中内置支持(因为是JavaScript的一个子集)以及相对于XML的简单性。CSⅤ是另一种流行的与语言无关的格式，尽管功能较弱。

​	JSON、XML和CSV都是文本格式，因此具有不错的可读性(尽管语法容易引发争论)。除了表面的语法问题之外，它们也有一些微妙的问题:

+ 数字编码有很多模糊之处。**在XML和CSV中，无法区分数字和碰巧由数字组成的字符串**(除了引用外部模式)。**JSON区分字符串和数字，但不区分整数和浮点数，并且不指定精度**。这在处理大数字时是一个问题，**<u>大于2<sup>53</sup>的整数在EEE754双精度浮点数中不能精确表示，所以这些数字在使用浮点数(如JavaScript)的语言中进行分析时，会变得不准确</u>**。 Twitter上有一个大于2<sup>53</sup>的数字的例子，它使用一个64位的数字来标识每条推文。 <u>Twitter的API返回的JSON包含两次推特ID，一次是JSON数字，一次是十进制字符串，以解决 JavaScript应用程序没有正确解析数字的问题</u>。
+ **JSON和XML对Unicode字符串(即人类可读文本)有很好的支持，但是它们不支持二进制字符串(没有字符编码的字节序列)**。二进制字符串是一个有用的功能，所以人们通过使用Base64将二进制数据编码为文本来解决这个限制。然后，模式可以表明该值应该被解释为Base64编码。虽然可行，但有点混乱，并且数据大小增加了33%。
+ XML和JSON都有可选的模式支持。这些模式语言相当强大，因此学习和实现起来也比较复杂。XML模式的使用相当广泛，但许多基于JSON的工具并不局限于使用模式。**由于数据(例如数字和二进制字符串)的正确解释取决于模式中的信息，因此不使用XML/JSON架构的应用程序可能不得不硬编码适当的编码/解码逻辑**。
+ **CSⅤ没有任何模式，因此应用程序需要定义毎行和每列的含义**。如果应用程序更改添加新的行或列，则必须手动处理该更改。<u>CSV也是一个相当模糊的格式(如果一个值包含逗号或换行符，会发生什么)。尽管其转义规则已经被正式指定，但并不是所有的解析器都能正确地实现它们</u>。

​	<u>尽管存在这些或那些缺陷，但JSON、XML和CSV已经可用于很多应用。特别是作为数据交换格式(即将数据从一个组织发送到另一个组织)，它们非常受欢迎。在这些情况下，**只要人们就格式本身达成一致，格式多么美观或者高效往往不太重要。让不同的组织达成格式一致的难度通常超过了所有其他问题**</u>。

#### 二进制编码

​	对于仅在组织内部使用的数据，使用最小公分母编码格式则较为顺畅。例如，可以选择更紧凑或更快的解析格式。对于一个小数据集来说，收益可以忽略不计，但一旦达到TB级别，数据格式的选择就会产生很大的影响。

​	JSON不像XML那么冗长，但与二进制格式相比，两者仍然占用大量空间。这种观察导致开发了大量的二进制编码，用以支持JSON(举几个例子，如MessagePack、BSON、 BJSON、 UBJSON、 BISON和Smile)和XML(如 WBXML和Fast Infoset)。这些格式已经被很多细分领域所采用，但是没有一个像JSON和XML那样被广泛采用。

​	其中一些格式还扩展了数据类型集(例如，区分整数和浮点数，或者增加对二进制字符串的支持)，但其他格式保持JSON/ⅩML数据模型不变。特别是，由于它们没有规定模式，所以需要在编码数据时包含所有的对象字段名称。也就是说，在示例4-1中的JSON文档的二进制编码中，它们将需要在某处包含字符串userName、favoriteNumber和interest。

​	示例4-1：一条样本记录，本章后续的多种二进制格式编码都以该记录来示例说明

```json
{
  "userName": "Martin",
  "favoriteNumber": 1337,
  "interests": ["daydreaming", "hacking"]
}
```

​	来看一个MessagePack的例子，它是一种JSON的二进制编码。图4-1展示了采用MessagePack示例4-1的JSON文档进行编码所得到的字节序列。前几个字节如下：

1. 第一个字节0x83，表示接下来是包含三个字段(最低四位=0×03)的对象(最高四位=0x80)(如果想知道当对象的字段数超过15个，4bit已经无法容纳，会发生什么情况。结果是，它会得到一个不同的类型指示符，并且字段数被编码为两个或四个字节)。
2. 第二个字节0xa8，表示接下来是八字节长的字符串(最高四位=0xa0，最低四位=0x08)。
3. 再往下的八字节是ASCI中的字段名称 userName。由于之前已经指出了长度，因此不需要任何标记来告诉字符串结束的位置(或任何转义)。
4. 接下来的七字节使用前缀oxa6对6个字母的字符串值Martin进行编码，依此类推。

​	二进制编码的长度为66字节，仅略小于文本JSON编码(去掉空格)占用的81字节。JSON的所有二进制编码在这方面是相似的。目前对于如此小的空间缩减(也许解析速度可以加快)是否值得失去可读性仍存有疑问。

​	在下面的章节中，我们将看到如何做得更好，只用32字节即可完成对同样的记录进行编码。

![编码数据的格式 - 图1](https://static.sitestack.cn/projects/ddia/img/fig4-1.png)

### * 4.1.3 Thrift与Protocol Buffers

​	Apache Thrift和Protocol Buffers(protobuf) 是基于相同原理的两种二进制编码库。Protocol Buffers最初是在Google开发的，Thrift最初是在Facebook开发的，并且都是在2007~2008年开源的。

​	Thrift和Protocol Buffers都需要模式来编码任意的数据。为了用Thrift示例4-1中的数据进行编码，可以使用 Thrift接口定义语言(IDL)来描述模式，如下所示：

```idl
struct Person {
    1: required string       userName,
    2: optional i64          favoriteNumber,
    3: optional list<string> interests
}
```

​	Protocol Buffers的等效模式定义看起来非常相似：

```protobuf
message Person {
    required string user_name       = 1;
    optional int64  favorite_number = 2;
    repeated string interests       = 3;
}
```

​	Thrift和Protocol Buffers有对应的代码生成工具，采用和上面类似的模式定义，并生成支持多种编程语言的类。应用程序可以直接调用生成的代码来编码或解码该模式的记录。

​	用这个模式编码的数据是什么样的？令人困惑的是，Thrift有两种不同的二进制编码格式，分别称为BinaryProtocol和CompactProtocol。先来看看BinaryProtocol，以这种格式编码示例4-1需要59字节，如图4-2所示。

![编码数据的格式 - 图2](https://static.sitestack.cn/projects/ddia/img/fig4-2.png)

​	与图4-1类似，每个字段都有一个类型注释(用于指示它是否是字符串、整数、列表等)，并且可以在需要时指定长度(包括字符串的长度、列表中的项数)。与之前类似，数据中出现的字符串("Martin"， "daydreaming"，"hacking")<u>也被编码为ASCII (或者更确切地说，UTF-8</u>)。

​	与图4-1相比，最大的区别是没有字段名( userName、 favoriteNumber和interest)。相反，编码数据包含数字类型的字段标签(1、2和3)。这些是模式定义中出现的数字。字段标签就像字段的别名，用来指示当前的字段，但更为紧凑，可以省去引用字段全名。

​	Thrift CompactProtocol编码在语义上等同于 Binary Protocol，但如图4-3所示，它将相同的信息打包成只有34字节。它通过将字段类型和标签号打包到单字节中，并使用可变长度整数来实现。对数字1337，不使用全部8字节，而是使用两个字节进行编码，每字节的最高位用来指示是否还有更多的字节。这意味着-64~63之间的数字被编码为一字节，-8192~8191之间的数字被编码成两个字节等。更大的数字需要更多字节。

![编码数据的格式 - 图3](https://static.sitestack.cn/projects/ddia/img/fig4-3.png)

​	最后， Protocol Buffers(只有一种二进制编码格式)对相同的数据进行编码，如图4-4所示。它的位打包方式略有不同，但与Thrift的CompactProtocol非常相似。 ProtocolBuffers只用33字节可以表示相同的记录。

![编码数据的格式 - 图4](https://static.sitestack.cn/projects/ddia/img/fig4-4.png)

​	需要注意的一个细节是，在前面所示的模式中，<u>每个字段被标记为required(必须)或optional(可选)，但这对字段如何编码没有任何影响(二进制数据中不会指示某宇段是否必须)。区别在于，如果字段设置了required，但字段未填充，则运行时检查将出现失败，这对于捕获错误非常有用</u>。

#### 字段标签和模式演化

​	之前说过，**模式不可避免地需要随着时间而不断变化，称之为模式演化**。那么 Thrift和 Protocol Buffers如何在保持向后和向前兼容性的同时应对模式更改呢?

​	从示例中可以看到，一条编码记录只是一组编码字段的拼接。每个字段由其标签号(示例模式中的数字1、2、3)标识，并使用数据类型(例如字符串或整数)进行注释。**如果没有设置字段值，则将其从编码的记录中简单地忽略**。由此可以看出，<u>字段标签(field tag)对编码数据的含义至关重要</u>。可以轻松更改模式中字段的名称，而编码永远不直接引用字段名称。但不能随便更改字段的标签，它会导致所有现有编码数据无效。

​	**可以添加新的字段到模式，只要给每个字段一个新的标记号码。<u>如果旧的代码(不知道添加的新标记号码)试图读取新代码写入的数据，包括一个它不能识别的标记号码中新的字段，则它可以简单地忽略该字段</u>。实现时，通过数据类型的注释来通知解析器跳过特定的字节数。这样可以实现向前兼容性，即旧代码可以读取由新代码编写的记录**。

​	向后兼容性呢？<u>只要每个字段都有一个唯一的标记号码，新的代码总是可以读取旧的数据，因为标记号码仍然具有相同的含义</u>。唯一的细节是，如果添加一个新的字段，则无法使其成为必需字段。如果要添加字段并将其设置为 required，当新代码读取旧代码写入的数据，则该检查将失败，因为旧代码不会写入添加的新字段。因此，**为了保持向后兼容性，在模式的初始部署之后添加的毎个字段都必须是可选的或具有默认值**。

​	**删除字段就像添加字段一样，不过向后和向前兼容性问题相反。这意味着<u>只能删除可选的字段(必填字段永远不能被删除)，而且不能再次使用相同的标签号码(因为可能仍然有写入的数据包含旧的标签号码，而该字段必须被新代码忽略)</u>**。

#### 数据类型和模式演化

​	<u>另外一个问题，如果改变字段的数据类型呢？这是有可能的(请检查文档以了解详细信息)，但存在值会丢失精度或被截断的风险。例如，假设将一个32位的整数变成个64位的整数。新代码可以容易地读取旧代码写入的数据，因为解析器可以用零填充任何缺失的位。但是，如果旧代码读取新代码写入的数据，旧代码仍然使用32位变量来保存该值。如果解码的64位值不适合32位，则它将被截断</u>。

​	Protocol Buffers的一个奇怪的细节是，它没有列表或数组数据类型，而是有字段的重复标记(repeated，这是必需和可选之外的第三个选项)。如图4-4所示，对于重复字段，表示同一个字段标签只是简单地多次出现在记录中。可以将可选(单值)字段更改为重复(多值)字段。<u>读取旧数据的新代码会看到一个包含零个或一个元素的列表取决于该字段是否存在)。读取新数据的旧代码只能看到列表的最后一个元素</u>。

​	Thrift 有专用的列表数据类型，它使用列表元素的数据类型进行参数化。它不支持Protocol Buffers那样从单值到多值的改变，但是它具有支持嵌套列表的优点。

### 4.1.4 Avro

​	Apache Avro是另一种二进制编码格式，它与 Protocol Buffers和Thrift有着一些有趣的差异。由于Thrift不适合 Hadoop用例，因此Avro在2000年作为Hadoop子项目而启动。

​	Avro也使用模式来指定编码的数据结构。它有两种模式语言：一种(Avro IDL)用于人工编辑，另一种(基于JSON)更易于机器读取。

​	用 Avro IDL编写的示例模式如下所示：

```idl
record Person {
    string                userName;
    union { null, long }  favoriteNumber = null;
    array<string>         interests;
}
```

该模式的等价JSON表示如下：

```json
{
    "type": "record",
    "name": "Person",
    "fields": [
        {"name": "userName", "type": "string"},
        {"name": "favoriteNumber", "type": ["null", "long"], "default": null},
        {"name": "interests", "type": {"type": "array", "items": "string"}
    ] 
}
```

​	首先，请注意模式中没有标签编号。如果使用这个模式编码示例记录(示例4-1)Avro二进制编码只有32字节长，这是所见到的所有编码中最紧凑的。编码字节序列的分解如图4-5所示。

![编码数据的格式 - 图5](https://static.sitestack.cn/projects/ddia/img/fig4-5.png)

​	如果检查图4-5的字节序列，可以看到<u>没有什么可以标识字段或数据类型</u>。编码只是由连在一起的一些列值组成。一个字符串只是一个长度前缀，后跟UTF-8字节流，但编码数据中没有任何内容告诉你它是一个字符串。它也可以是一个整数，或者其他什么类型。整数使用可变长度编码(与Thrift的CompactProtocol相同)进行编码。

​	<u>为了解析二进制数据，按照它们出现在模式中的顺序遍历这些字段，然后直接采用模式告诉你每个字段的数据类型。这意味着，只有当读取数据的代码使用与写入数据的代码完全相同的模式时，才能正确解码二进制数据。读和写的模式如果有任何不匹配都将无法解码数据</u>。

​	那么，Avro如何支持模式演化?

#### 写模式与读模式

​	有了Avro，当应用程序想要对某些数据进行编码(例如将其写入文件或数据库，以及通过网络发送)时，它使用所知道的模式的任何版本来编码数据，例如，可以编译到应用程序中的模式。这被称为写模式。

​	当应用程序想要解码某些数据(例如从文件或数据库读取数据，或者从网络接收数据等)时，它期望数据符合某个模式，即读模式。这是应用程序代码所依赖的模式，代码可能是在应用程序的构建过程中基于模式而动态生成。

​	<u>Avro的关键思想是，写模式和读模式不必是完全一模一样，它们只需保持兼容</u>。当数据被解码(读取)时，Avro库通过对比査看写模式和读模式并将数据从写模式转换为读模式来解决其差异。Avro规范明确定义了这种解决方法的工作原理，如图4-6所示。

​	<u>例如，如果写模式和读模式的字段顺序不同，这也没有问题，因为模式解析通过字段名匹配字段。如果读取数据的代码遇到岀现在写模式但不在读模式中的字段，则忽略它。如果读取数据的代码需要某个字段，但是写模式不包含该名称的字段，则使用在读模式中声明的默认值填充</u>。

#### 模式演化规则

​	<u>使用Avro，向前兼容意味着可以将新版本的模式作为writer，并将旧版本的模式作为reader。相反，向后兼容意味着可以用新版本的模式作为reader，并用旧版本的模式作为writer</u>。

​	**为了保持兼容性，只能添加或删除具有默认值的字段(在Avro模式中，字段favourNumber的默认值为null)**。例如，假设添加了一个带有默认值的字段，则此新字段存在于新模式中，而不是旧模式中。当使用新模式的reader读取使用旧模式写入的记录时，将为缺少的字段填充默认值。

![编码数据的格式 - 图6](https://static.sitestack.cn/projects/ddia/img/fig4-6.png)

​	<u>如果要添加一个没有默认值的字段，新的 reader将无法读取旧的 writer写的数据，因此将破坏向后兼容性。如果要删除没有默认值的字段，旧 reader将无法读取新 writer写入的数据，因此将破坏向前兼容性</u>。

​	在某些编程语言中，null是所有变量可以接受的默认值。但在Avro中并非如此：如果要允许字段为null，则必须使用联合类型。例如，`union{null, long, string}`字段；表示该字段可以是数字、字符串或null。只有当null是联合的分支之一时，才可以使用它作为默认值。这比默认情况下所有类型都可为空显得更加冗长一些，但是通过明确什么能为null和不能为null可以帮助防止一些错误。

​	因此，Avro不像 Protocol Buffers和 Thrift 那样具有可选和必需的标签(而是有联合类型和默认值)。

​	只要 Avro 可以转换类型，就可以改变字段的数据类型。更改字段的名称也是可能的，但有点棘手: reader的模式可以包含字段名称的别名，因此它可以将旧writer模式字段名称与别名进行匹配。这意味着更改字段名称是向后兼容的，但不能向前兼容。同样，向联合类型添加分支也是向后兼容的，但不能向前兼容。

#### * 那么writer模式又是什么？

​	到目前为止，忽略了一个重要的问题: reader如何知道特定的数据采用哪个 writer的模式编码的？在每个记录中都包含整个模式不太现实，因为模式有时甚至比编码数据还要大得多，这样二进制编码所节省的空间都变得没有意义。

​	答案取决于Avro使用的上下文。举几个例子:

+ 有很多记录的大文件

  Avro的一个常见用途，尤其是在Hadoop的上下文中，是用于存储包含数百万条记录的大文件，所有记录都使用相同的模式进行编码(将在第10章讨论这种情况)。在这种情况下，<u>该文件的 writer可以仅在文件的开头包含 writer的模式信息</u>。Avro通过指定一个文件格式(对象容器文件)来做到这一点。

+ 具有单独写入记录的数据库

  在数据库中，不同的记录可能在不同的时间点、使用不同的 writer模式编写，不能假设所有记录都具有相同的模式。<u>最简单的解决方案是在每个编码记录的开始处包含一个版本号，并在数据库中保留一个模式版本列表</u>。 **reader可以获取记录，提取版本号，然后从数据库中査询该版本号的 writer模式。使用该 writer模式，它可以解码记录的其余部分**。例如 Espresso是这样工作的。

+ 通过网络连接发送记录

  **当两个进程通过双向网络连接进行通信时，他们可以在建立连接时协商模式版本，然后在连接的生命周期中使用该模式。这也是 Avro RPC协议(参阅本章后续的"基于服务的数据流：REST和RPC")的基本原理**。

​	在任何情况下，提供一个模式版本信息的数据库都非常有用，它可以充当一个说明文档来检査模式兼容性情况。至于版本号，可以使用简单的递增整数，也可以使用对模式的哈希。

#### 动态生成的模式

​	**与Protocol Buffers和Thrift比，Avro方法的一个优点是不包含任何标签号**。为什么这很重要？在模式中保留一些数字有什么问题？

​	**关键之处在于Avro对动态生成的模式更友好**。例如，假如有一个关系数据库，想要把它的内容转储到一个文件中，并且希望使用二进制格式来避免上述文本格式(JSON、CSV、SQL)的问题。如果使用Avro，可以很容易地根据关系模式生成Avro模式，并使用该模式对数据库内容进行编码，然后将其全部转储到Avro对象容器文件中。可以为每个数据库的表生成对应的记录模式，而每个列成为该记录中的个字段。数据库中的列名称映射到Avro中的字段名称。

​	现在，如果数据库模式发生变化(例如，表中添加了一列，删除了一列)，则可以从更新的数据库模式生成新的Avro模式，并用新的Avro模式导出数据。数据导出过程不需要关注模式的改变，每次运行时都可以简单地进行模式转换。<u>任何读取新数据文件的人都会看到记录的字段已经改变，但是由于**字段是通过名字来标识**的，所以更新的writer模式仍然可以与旧的reader模式匹配</u>。

​	相比之下，如果使用 Thrift或 Protocol Buffers，则可能必须手动分配字段标签：每次数据库模式更改时，管理员都必须手动更新从数据库列名到字段标签的映射(这可能会自动化，但模式生成器必须非常小心，不要分配以前使用的字段标签)。这种动态生成的模式根本不是 Thrift或 Protocol Buffers的设计目标，而是Avro的设计目标。

#### 代码生成和动态类型语言

​	Thrift和Protocol Buffers依赖于代码生成：在定义了模式之后，可以使用选择的编程语言生成实现此模式的代码。这在Java、C++或C#等静态类型语言中很有用，因为它允许使用高效的内存结构来解码数据，并且在编写访问数据结构的程序时，支持在IDE中进行类型检查和自动完成。

​	<u>在动态类型编程语言中，如 JavaScript、Ruby或 Python，因为没有编译时类型检査，生成代码没有太多意义。代码生成在这些语言中经常被忽视，因为他们避免了明确的编译步骤</u>。**此外，对于动态生成的模式(例如从数据库表生成的Avro模式)的情况，代码生成对获取数据反而是不必要的障碍**。

​	Avro为静态类型编程语言提供了可选的代码生成，但是它也可以在不生成代码的情况下直接使用。如果有一个对象容器文件(它嵌入了 writer模式)，可以简单地使用Avro库打开它，并用和查看JSON文件一样的方式查看数据。**该文件是自描述的，它包含了所有必要的元数据**。

​	此属性与动态类型数据处理语言(如 Apache Pig)结合使用时特别有用。在 Apache Pig中，只需打开一些Avro文件，分析其内容，并编写派生数据集以Avro格式输出文件，而无需考虑模式。

### 4.1.5 模式的优点

​	正如上述所介绍的， Protocol Buffers、 Thrift和 Avro都使用了模式来描述二进制编码格式。它们的模式语言比XML模式或JSON模式简单得多，它支持更详细的验证规则(例如，“该字段的字符串值必须匹配此正则表达式”或“该字段的整数值必须介于0~100间”)。由于 Protocol Buffers、 Thrift和Avro的实现更简单，使用更简单，它们已经得到了非常广泛的编程语言支持。

​	不过，这些编码背后的思想绝不是什么新鲜事物。例如，它们与ASN.1有很多相似之处，ASN.1是在1984年首次被标准化的模式定义语言。ASN.1被用来定义各种网络协议，其二进制编码(DER)仍然被用于编码SSL证书(X.509)。ASN.1支持使用标签号的模式演化，类似于 Protocol buffers和 Thrift2。然而，它非常复杂，并且文档不尽如人意，所以ASN.1可能不是新型应用的最佳选择。

​	许多数据系统也实现了一些专有的二进制编码。例如，大多数关系数据库都有网络协议，可以通过该协议向数据库发送查询并获取响应。这些协议通常用于特定的数据库，并且数据库供应商提供驱动程序(例如，使用ODBC或 JDBC API)，把来自数据库的网络协议的响应解码为内存数据结构。

​	所以我们看到，尽管JSON、XML和CSⅤ等文本数据格式非常普遍，但基于模式的进制编码也是一个可行的选择。它们有许多不错的属性：

+ 它们可以比各种“二进制JSON”变体更紧凑，可以省略编码数据中的字段名称。
+ 模式是一种有价值的文档形式，因为模式是解码所必需的，所以可以确定它是最新的(而手动维护的文档可能很容易偏离现实)。
+ **模式数据库允许在部署任何内容之前检查模式更改的向前和向后兼容性**。
+ 对于静态类型编程语言的用户来说，从模式生成代码的能力是有用的，它能够在编译时进行类型检查。

​	总之，通过演化支持与无模式/读时模式的JSON数据库相同的灵活性(参阅第2章“文档模型中的模式灵活性”)，同时还提供了有关数据和工具方面更好的保障。

## 4.2 数据流模式

​	本章开始时，我们提到，每当将一些数据发送到非共享内存的另一个进程时，例如，当通过网络发送数据或者把它写入文件时，都需要将数据编码为字节序列。然后，讨论了用于执行此操作的各种不同编码技术。

​	而向前和向后的兼容性对于可演化性来说非常重要，通过允许独立升级系统的不同部分，而不必一次改变所有，使更改更为容易。兼容性是执行编码的一个进程和执行解码的另一个进程之间的关系。

​	这是一个相当抽象的想法，数据可以通过多种方式从一个进程流向另一个进程。谁编码数据？谁解码数据？在本章的其余部分，将探讨一些最常见的进程间数据流动的方式：

+ 通过数据库(参阅本章后面的“基于数据库的数据流”部分)。
+ 通过服务调用(参阅本章后面的“基于服务的数据流:REST和RPC”部分)。
+ 通过异步消息传递(参阅本章后面的“基于消息传递的数据流”部分)。

### 4.2.1 基于数据库的数据流

​	在数据库中，写入数据库的进程对数据进行编码，而读取数据库的进程对数据进行解码。可能只有一个进程访问数据库，在这种情况下， reader只是同一进程的较新版本，此时，可以认为向数据库中存储内容，就是给未来的自己发送消息。

​	在这种情况下，向后兼容性显然是必要的；否则未来的自己将无法解码以前写的东西。

​	一般而言，几个不同的进程同时访问数据库是很常见的。这些进程可能是几个不同的应用程序或服务，也可能只是同一服务的几个实例(为了可伸缩性或容错并行运行)。无论哪种情况，在应用程序正在改变的环境中，访问数据库的某些进程可能运行较新的代码，而某些进程可能运行较旧的代码。例如，因为当前正在滚动升级中部署新版本，所以某些实例已经更新，而其他实例尚末更新。

​	这意味着数据库中的值可以由较新版本的代码写入，然后由仍在运行的旧版本代码读取。因此，数据库通常也需要向前兼容。

​	然而，还有一个额外的障碍。假设在记录模式中添加了一个字段，并且较新的代码将该新字段的值写入数据库。随后，旧版本的代码(尚不知道该新字段)将读取、更新记录并将其写回。在这种情况下，理想的行为通常是旧代码保持新字段不变，即使它无法解释。

​	之前讨论的編码格式支持未知字段的保存，但是有时候还需要注意应用程序层面的影响，如图4-7所示。例如，如果将数据库值解码为应用程序中的模型对象，然后重新编码这些模型对象，则在该转换过程中可能会丢失未知字段。解决这个问题并不困难，重要的是首先要有这方面的意识。

#### 不同的时间写入不同的值

​	数据库通常支持在任何时候更新任何值。这意味着在单个数据库中，可能有一些值是在5ms前写入的，而有些值是在5年前写入的。

​	部署新版本的应用程序(至少是服务器端应用程序)时，可能会在几分钟内用新版本完全替换旧版本。数据库内容的情况并不是这样：五年前的数据仍然采用原始编码，除非已经明确地重写了它。这种现象有时被总结为数据比代码更长久。

![数据流的类型 - 图1](https://static.sitestack.cn/projects/ddia/img/fig4-7.png)

​	将数据重写(或迁移)为新模式当然是可能的，但在大型数据集上执行此操作代价不菲，因此很多数据库都尽可能避免此操作。大多数关系数据库允许进行简单的模式更改，例如添加具有默认值为空的新列，而不重写现有数据。读取旧行时，数据库会为磁盘上编码数据缺失的所有列填充为空值。 LinkedIn的文档数据库Espresso使用Avro进行存储，并支持Avro的模式演化规则。

​	因此，<u>模式演化支持整个数据库看起来像是采用单个模式编码，即使底层存储可能包含各个版本模式所编码的记录。</u>

#### 归档存储

​	或许你会不时地为数据库创建快照，例如用于备份或加载到数据仓库(参阅第3章的数据仓库”部分)。在这种情况下，数据转储通常使用最新的模式进行编码，即使源数据库中的原始编码包含了不同时代的各种模式版本。由于无论如何都要复制数据，所以此时最好对数据副本进行统一的编码。

​	由于数据转储是一次写入的，而且以后不可改变，因此像Avro对象容器文件这样的格式非常适合。这也是很好的机会，可以用分析友好的列存储(如Parquet)对数据进行编码(参阅第3章的“列压缩”部分)。

​	在第10章中，将详细讨论如何在归档存储中使用数据。

### 4.2.2 基于服务的数据流： REST和RPC

​	对于需要通过网络进行通信的进程，有多种不同的通信方式。最常见的是有两个角色：客户端和服务器。服务器通过网络公开API，客户端可以连接到服务器以向该API发出请求。服务器公开的API称为服务。

​	Web的工作方式是：客户端(Web浏览器)向Web服务器发出请求，发出GET请求来下载HTML、CSS、 JavaScript、图像等，发出POST请求提交数据到服务器。API包含一组标准的协议和数据格式(HTTP、URL、SSL/TLS、HTML等)。因为Web浏览器、Web服务器和网站作者大多同意这些标准，所以可以使用任何浏览器访问任何网站(至少在理论上)。

​	Web浏览器不是唯一的客户端类型。例如，在移动设备或桌面计算机上运行的本地应用程序也可以向服务器发出网络请求，并且在Web浏览器内运行的客户端JavaScript，应用程序可以使用XMLHttpRequest成为HTTP客户端(该技术被称为Ajax)。在这种情况下，服务器的响应通常不是用于展示给用户的HTML，而是便于客户端应用程序代码进一步处理的编码数据(如JSON)。虽然HTTP可以用作传输协议，但是在顶层实现的API是特定于应用程序的，客户端和服务器需要就该API的细节达成一致。

​	此外，服务器本身可以是另一项服务的客户端(例如，典型的Web应用服务器作为数据库的客户端)。这种方法通常用于将大型应用程序按照功能区域分解为较小的服务，这样当一个服务需要另一个服务的某些功能或数据时，就会向另一个服务发出请求。这种构建应用程序的方式传统上被称为面向服务的体系结构(service-oriented architecture，SOA)，最近则更名为微服务体系结构(microservices architecture)。

​	在某些方面，服务类似于数据库：它们通常允许客户端提交和查询数据。然而，虽然数据库支持使用第2章中讨论的查询语言进行任意查询，但服务公开了特定于应用程序的API，它只允许由服务的业务逻辑(应用程序代码)预先确定的输入和输出。此限制提供了一定程度的封装：服务可以对客户端可以做什么和不能做什么施加细粒度的限制。

​	面向服务微服务体系结构的一个关键设计目标是，通过使服务可独立部署和演化，让应用程序更易于更改和维护。例如，每个服务应该由一个团队拥有，该团队应该能够经常发布新版夲的服务，而不必与其他团队协调。换句话说，应该期望新旧版本的服务器和客户端同时运行，因此服务器和客户端使用的数据编码必须在不同版本的服务API之间兼容，这正是在本章所讨论的内容。

#### 网络服务

​	当HTTP被用作与服务通信的底层协议时，它被称为Web服务。这可能有点用词不当，因为Web服务不仅在Web上使用，而且在几个不同的上下文中使用。例如：

1. 运行在用户设备上的客户端应用程序(例如，移动设备上的本地应用程序，或使用Ajax的JavaScriptWeb应用程序)，通过HTTP向服务发出请求。这些请求通常通过公共互联网进行。
2. 一种服务向同一组织拥有的另一项服务提出请求，这些服务通常位于同一数据中心内，作为面向服务/微型架构的一部分。支持这种用例的软件有时被称为中间件。
3. 一种服务向不同组织所拥有的服务提出请求，经常需通过互联网。这用于不同组织后端系统之间的数据交换。此类别包括由在线服务(如信用卡处理系统)提供的公共API，或用于共享访问用户数据的OAuth。

​	有两种流行的Web服务方法：REST和SOAP。它们在设计理念方面几乎是截然相反的，也往往是各自支持者之间激烈辩论的主题。

​	**REST不是一种协议，而是一个基于HTTP原则的设计理念。它强调简单的数据格式，使用URL来标识资源，并使用HTTP功能进行缓存控制、身份验证和内容类型协商**。与SOAP相比，REST已经越来越受欢迎，至少在跨组织服务集成的背景下，并经常与微服务相关联。根据REST原则所设计的API称为RESTful。

​	相比之下，SOAP是一种基于XML的协议，用于发出网络API请求。虽然它最常用于HTTP，但其目的是独立于HTTP，并避免使用大多数HTTP功能。相反，它带有庞大而复杂的多种相关标准(Web服务框架， Web Service Framework，称为WS-*)和新增的各种功能。

​	SOAP Web服务的API使用被称为WSDL(Web Services Description Language，一种基于XML的语言)来描述。WSDL支持代码生成，客户端可以使用本地类和方法调用(编码为XML消息并由框架再次解码)来访问远程服务。这在静态类型编程语言中非常有用，但在动态类型编程语言中用处不大(参阅本章前面的“代码生成和动态类型化语言”部分)。

​	由于WSDL的设计目标不是人类可读的，而且SOAP消息通常过于复杂，无法手动构建，SOAP用户严重依赖工具支持、代码生成和IDE。对于没有SOAP供应商支持的编程语言的用户来说，试图与SOAP服务集成非常困难。

​	尽管SOAP及其各种扩展表面上是标准化的，但是不同厂商的实现之间的互操作性往往存在一些问题。由于所有这些原因，尽管它仍然被许多大型企业使用，但已经不再受到大多数小公司的青睞。

​	RESTful的API倾向于更简单的方法，通常涉及较少的代码生成和自动化工具。定义格式如OpenAPI，也称为 Swagger，可用于描述RESTful API并帮助生成文档。

#### * 远程过程调用(RPC)的问题

​	Web服务仅仅是通过网络发出API请求的一系列技术的最新体现，其中许多技术受到了大肆宣传，但也存在严重的问题。企业级 JavaBeans(EJB)和Java的远程方法调用(RMI)仅限于Java。分布式组件对象模型(DCOM)仅限于 Microsoft平台。公共平台对象请求代理体系结构(CORBA)过于复杂，不提供向前或向后兼容性。

​	所有这些都是基于远程过程调用(Remote Procedure Call，RPC)的思想，该思想自20世纪70年代以来就一直存在。RPC模型试图使向远程网络服务发出请求看起来与在同一进程中调用编程语言中的函数或方法相同(这种抽象称为位置透明)。虽然RPC起初看起来很方便，但这种方法在根本上是有缺陷的。网络请求与本地函数调用非常不同：

+ 本地函数调用是可预测的，并且成功或失败仅取决于控制的参数。网络请求是不可预测的：请求或响应可能由于网络问题而丟失，或者远程计算机可能速度慢或不可用，这些问题完全不在控制范围之内。<u>网络问题很常见，因此必须有所准备，例如重试失败的请求。</u>
+ 本地函数调用要么返回一个结果，要么抛出一个异常，或者永远不会返回(因为进入无限循环或者进程崩溃)。<u>网络请求有另一个可能的结果：由于超时，它返回时可能没有结果。在这种情况下，根本不知道发生了什么：如果没有收到来自远程服务的响应，无法知道请求是否成功</u>。我们将在第8章更详细地讨论此类问题。

+ <u>如果重试失败的网络请求，可能会发生请求实际上已经完成，只是响应丢失的情况</u>。在这种情况下，重试将导致该操作被执行多次，除非在协议中建立重复数据消除(**幂等性**)机制。本地函数调用则没有这样问题。在第11章更详细地讨论幂等性。
+ 每次调用本地函数时，通常需要大致相同的时间来执行。网络请求比函数调用要慢得多，而且其延迟也有很大的变化：情况好时，它可能会在不到1ms的时间内完成，但是当网络拥塞或者远程服务过载时，可能需要几秒钟的时间才能完成相同操作。
+ 调用本地函数时，可以高效地将引用(指针)传递给本地内存中的对象。当发出网终请求时，所有这些参数都需要被编码成可以通过网络发送的字节序列。如果参数是像数字或字符串这样的基本类型，这没关系，但是对于较大的对象很快就会出现问题。
+ <u>客户端和服务可以用不同的编程语言来实现，所以RPC框架必须将数据类型从种语言转换成另一种语言。因为不是所有的语言都具有相同的类型，所以最终可能会丑陋</u>。例如，回想一下 JavaScript的数字大于2<sup>53</sup>的问题(参阅本章前面的"JSON、XML与二进制变体"部分)。用单一语言编写的单个进程中不存在此问题。

​	所有这些因素意味着，尝试使远程服务看起来像编程语言中的本地对象一样毫无意义，因为它们是根本不同的事情。REST的部分吸引力在于，它并不试图隐藏它是网络协议的事实(尽管这似乎并没有阻止人们在REST之上构建RPC库)。

#### RPC的发展方向

​	虽然有这些问题，但是RPC并没有消失。在本章提到的所有编码的基础上构建了各种RPC框架：例如 Thrifti和Avro带有RPC支持，gRPC是使用 Protocol Buffers的RPC实现，Finagle也使用Thrift，Rest.li使用HTTP上的JSON。

​	<u>新一代的RPC框架更加明确了远程请求与本地函数调用不同的事实</u>。例如， Finagle和Rest.li使用Futures(Promises)来封装可能失败的异步操作。 Futures还简化了需要并行请求多项服务的情况，并将其结果合并。gRPC支持流，其中调用不仅包括一个请求和一个响应，还包括一段时间内一系列的请求和响应。

​	其中一些框架还提供了服务发现，即允许客户端查询在哪个IP地址和端口号上获得特定的服务。我们将在第6章“请求路由”回到该主题。

​	使用二进制编码格式的自定义RPC协议，可以实现比诸如REST上的JSON之类的通用协议更好的性能。但是， <u>RESTful API还有其他一些显著的优点：它有利于实验和调试(只需使用Web浏览器或命令行工具curl即可向它发出请求，而无需任何代码生成或软件安装)，支持所有的主流编程语言和平台，并且有一个庞大的工具生态系统(服务器、缓存、负载平衡器、代理、防火墙、监控、调试工具、测试工具等)</u>。

​	由于这些原因，REST似乎是公共API的主流风格。RPC框架主要侧重于同一组织内多项服务之间的请求，通常发生在同一数据中心内。

#### RPC 的数据编码和演化

​	对于演化性，重要的是可以独立地更改和部署RPC客户端和服务器。与基于数据库的数据流相比(如上一节所述)，此处可以做一个简化的假设：假定所有的服务器都先被更新，其次是所有的客户端。因此，只需要在请求上具有向后兼容性，而在响应上具有向前兼容性。

​	RPC方案的向后和向前兼容性属性取决于它所使用的具体编码技术：

+ Thrift、gRPC(Protocol Buffers)和Avro RPC可以根据各自编码格式的兼容性规则进行演化。
+ 在SOAP中，请求和响应是用XML模式指定的。这些都是可以演化的，但有一些微妙的陷阱。
+ RESTful API通常使用JSON(没有正式指定的模式)用于响应，而请求则采用JSON或URI编码/表单编码的请求参数。为了保持兼容性，通常考虑的更改包括添加可选的请求参数和在响应中添加新的字段。

​	**如果RPC经常用于跨组织边界的通信，则服务的兼容性会变得更加困难，服务的提供者经常无法控制其客户，也不能强制他们升级。因此，需要长期保持兼容性，也许是无限期的。如果不得不进行一些破坏兼容性的更改，则服务提供者往往会同时维护多个版本的服务API**。

​	关于API版本管理应该如何工作(即客户端如何指示它想要使用哪个版本的API没有统一的方案。**对于RESTful API，常用的方法是在URL或HTTP Accept头中使用版本号。对于使用API密钥来标识特定客户端的服务，另一种选择是将客户端请求的API版本存储在服务器上，并允许通过单独的管理接口更新该版本选项**。

### * 4.2.3 基于消息传递的数据流

​	我们一直在研究从一个进程到另一个进程不同的数据流编码方式。到目前为止，已经讨论了REST和RPC(其中一个进程通过网络向另一个进程发送请求，并期望尽快得到响应)以及数捃库(其中一个进程写入编码数据，另一个进程在将来某个时刻再次读取该数据)。

​	在最后一节中，将简要介绍一下RPC和数据库之间的异步消息传递系统。它们与RPC的相似之处在于，客户端的请求(通常称为消息)以低延迟传递到另一个进程。它们与数据库的相似之处在于，不是通过直接的网络连接发送消息，而是通过称为消息代理(也称为消息队列，或面向消息的中间件)的中介发送的，该中介会暂存消息。

​	与直接RPC相比，使用消息代理有以下几个优点:

+ **如果接收方不可用或过载，它可以充当缓冲区，从而提高系统的可靠性**。
+ **它可以自动将消息重新发送到崩溃的进程，从而防止消息丢失**。
+ 它避免了发送方需要知道接收方的IP地址和端口号(这在虚拟机经常容易起起停停的云部署中特别有用)。
+ **它支持将一条消息发送给多个接收方**。
+ **它在逻辑上将发送方与接收方分离**(发送方只是发布消息，并不关心谁使用它们)。

​	然而，**与RPC的差异在于，消息传递通信通常是单向的：发送方通常不期望收到对其消息的回复**。进程可能发送一个响应，但这通常是在一个独立的通道上完成的。这种通信模式是异步的：发送者不会等待消息被传递，而只是发送然后忘记它。

#### 消息代理

​	过去，消息代理主要由 TIBCO、 IBM WebSphere和 WebMethods等公司的商业软件所控制。最近，像 RabbitMQ、 ActiveMQ、 HornetQ、NATS和 Apache Kafka这样的开源实现已经流行起来。我们将在第11章对它们进行更详细的比较。

​	详细的传递语义因实现和配置而异，但**通常情况下，消息代理的使用方式如下：一个进程向指定的队列或主题发送消息，并且代理确保消息被传递给队列或主题的一个或多个消费者或订阅者**。**在同一主题上可以有许多生产者和许多消费者**。

​	<u>主题只提供单向数据流。但是，消费者本身可能会将消息发布到另一个主题(因此可以将它们链接在一起，就像将在第11章中看到的那样)，也可以发送到一个回复队列，该队列由原始消息发送者来消费(这样支持类似RPC的请求响应数据流)</u>。

​	消息代理通常不会强制任何特定的数据模型，消息只是包含一些元数据的字节序列，因此可以使用任何编码格式。如果编码是向后和向前兼容的，则可以最大程度灵活地独立更改发布者和消费者，并以任意顺序部署他们。

​	如果消费者重新发布消息到另一个主题，则可能需要小心保留未知字段，以防止前面在数据库上下文中描述的问题(见图47)。

#### 分布式Actor框架

​	**Actor模型是用于单个进程中并发的编程模型**。<u>逻辑被封装在 Actor中，而不是直接处理线程(以及竞争条件、锁定和死锁的相关问题)。每个Actor通常代表一个客户端或实体，它可能具有某些本地状态(不与其他任何 Actor共享)，并且它通过发送和接收异步消息与其他 Actor通信。**不保证消息传送：在某些错误情况下，消息将丢失**。由于每个Actor一次只处理一条消息，因此不需要担心线程，每个Actor都可以由框架独立调度</u>。

​	在分布式Actor框架中，这个编程模型被用来跨越多个节点来扩展应用程序。无论发送方和接收方是在同一个节点上还是在不同的节点上，都使用相同的消息传递机制。如果它们位于不同的节点上，则消息被透明地编码成字节序列，通过网络发送，并在另一端被解码。

​	相比RPC，位置透明性在Actor模型中更有效，因为Actor模型已经假定消息可能会丢失，即使在单个进程中也是如此。尽管网络上的延迟可能比同一个进程中的延迟更高，但是在使用Actor模型时，本地和远程通信之间根本上的不匹配所发生的概率更小。

​	<u>分布式的 Actor框架实质上是将消息代理和 Actor编程模型集成到单个框架中。但是如果要对基于 Actor的应用程序执行滚动升级，则仍需担心向前和向后兼容性问题，因为消息可能会从运行新版本的节点发送到运行旧版本的节点，反之亦然</u>。

​	三种流行的分布式 Actor框架处理消息编码的方式如下：

+ 默认情况下，Akka使用Java的内置序列化，它不提供向前或向后兼容性。但是，可以用类似 Protocol Buffers的东西替代它，从而获得滚动升级的能力。
+ 默认情况下， Orleans使用不支持滚动升级部署的自定义数据编码格式；要部署新版本的应用程序，需要建立一个新的集群，将流量从旧集群导入到新集群，然后关闭旧集群。像Akka一样，也可以使用自定义序列化插件。
+ 在Erlang OTP中，很难对记录模式进行更改(尽管系统具有许多为高可用性而设计的功能)。滚动升级在技术上是可能的，但要求仔细规划。一些实验性的新型映射数据类型(2014年在 Erlang R17中引入的类似于JSON的结构)可能会使模式的更改在将来变得更容易。

## 4.3 小结

​	本章，我们研究了将内存数据结构转换为网络或磁盘上字节流的多种方法。我们看到这些编码的细节不仅影响其效率，更重要的是还影响应用程序的体系结构和部署时的支持选项。

​	**特别地，许多服务需要支持滚动升级，即每次将新版本的服务逐步部署到几个节点，而不是同时部署到所有节点。<u>滚动升级允许在不停机的情况下发布新版本的服务(因此鼓励频繁地发布小版本而不是大版本)，并降低部署风险(允许错误版本在影响大量用户之前检测并回滚)</u>。这些特性非常有利于应用程序的演化和更改**。

​	**<u>在滚动升级期间，或者由于各种其他原因，必须假设不同的节点正在运行应用代码的不同版本</u>。因此，在系统内流动的所有数据都以提供向后兼容性(新代码可以读取旧数据)和向前兼容性(旧代码可以读取新数据)的方式进行编码显得非常重要**。

​	本章还讨论了多和数据编码格式及其兼容性情况：

+ 编程语言特定的编码仅限于某一种编程语言，往往无法提供向前和向后兼容性。
+ JSON、XML和CSV等文本格式非常普遍，其兼容性取决于你如何使用他们。它们有可选的模式语言，这有时是有用的，有时却是一个障碍。<u>这些格式对某些数据类型的支持有些模糊，必须小心处理数字和二进制字符串等问题</u>。
+ 像 Thrift、 Protocol Buffers和Avro这样的二进制的模式驱动格式，文持使用清晰定义的向前和向后兼容性语义进行紧凑、高效的编码。<u>这些模式对于静态类型语言中的文档和代码生成非常有用。然而，它们有一个缺点，即只有在数据解码后才是人类可读的</u>。

​	我们还讨论了数据流的几种模型，说明了数据编码在不同场景下非常重要：

+ 数据库，其中写入数据库的进程对数据进行编码，而读取数据库的进程对数据进行解码。
+ RPC和REST API，其中客户端对请求进行编码，服务器对请求进行解码并对响应进行编码，客户端最终对响应进行解码。

+ **异步消息传递(使用消息代理或Actor)，节点之间通过互相发送消息进行通信，消息由发送者编码并由接收者解码**。

​	最后，我们可以得出这样的结论，只要稍加小心，向后/向前兼容性和滚动升级是完全可以实现的。预祝你的应用程序可以快速迭代，顺利部署。
